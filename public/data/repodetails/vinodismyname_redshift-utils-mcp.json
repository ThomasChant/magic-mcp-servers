{
  "mcp_name": "vinodismyname/redshift-utils-mcp",
  "mcp_description": "Facilitates AI-driven interaction with Amazon Redshift, enabling secure data querying and diagnostics via the AWS Data API.",
  "mcp_id": "vinodismyname_redshift-utils-mcp",
  "fetch_timestamp": "2025-06-23T09:18:53.753916Z",
  "github_url": "https://github.com/vinodismyname/redshift-utils-mcp",
  "repository": {
    "name": "redshift-utils-mcp",
    "full_name": "vinodismyname/redshift-utils-mcp",
    "description": "ü§ñ Enable AI assistants (Claude, Cursor) to monitor, diagnose, and query Amazon Redshift using this MCP server and the AWS Data API.",
    "html_url": "https://github.com/vinodismyname/redshift-utils-mcp",
    "created_at": "2025-04-28T14:10:05Z",
    "updated_at": "2025-06-12T19:38:43Z",
    "pushed_at": "2025-04-30T02:47:28Z",
    "size": 2595,
    "stargazers_count": 3,
    "watchers_count": 3,
    "forks_count": 1,
    "open_issues_count": 0,
    "language": "Python",
    "license": "MIT License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "vinodismyname",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/14818465?v=4",
      "html_url": "https://github.com/vinodismyname"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 1,
    "subscribers_count": 1,
    "languages": {
      "Python": 101597
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 3,
    "contributors_count": 3,
    "latest_release": {
      "tag_name": "v0.3.1",
      "name": "Release v0.3.1 - Initial Release",
      "published_at": "2025-04-28T22:06:24Z",
      "body": "üöÄ **Initial release of the Redshift Admin MCP Server!**\r\n\r\nThis is the first version of the server, designed to bridge the gap between AI assistants (like Claude, Cursor, etc.) and your Amazon Redshift data warehouse using the Model Context Protocol (MCP). It leverages the AWS Redshift Data API for secure and simplified interactions.\r\n\r\n## ‚ú® Features\r\n\r\n*   **MCP Server Foundation:** Built using the `mcp` Python library.\r\n*   **Secure Redshift Connection:** Connects via AWS Redshift Data API using Boto3, configured via AWS Secrets Manager ARN and standard AWS credentials (environment variables, profiles, IAM roles).\r\n*   **Command-Line Interface:** Basic CLI powered by `Typer` for starting the server and managing configuration overrides (`src/redshift_utils_mcp/__main__.py`).\r\n*   **Core MCP Tools Implemented:**\r\n    *   `handle_check_cluster_health`: Performs basic/full health checks using diagnostic SQL scripts.\r\n    *   `handle_diagnose_locks`: Identifies lock contention and blocking PIDs.\r\n    *   `handle_diagnose_query_performance`: Analyzes performance metrics, plan, and history for a specific query ID.\r\n    *   `handle_execute_ad_hoc_query`: Allows execution of arbitrary (read-only intended) SQL queries.\r\n    *   `handle_get_table_definition`: Retrieves table DDL using `SHOW TABLE`.\r\n    *   `handle_inspect_table`: Gathers comprehensive details about a table (design, storage, health, usage).\r\n    *   `handle_monitor_workload`: Analyzes workload patterns over a time window.\r\n*   **MCP Resources Implemented:**\r\n    *   `/scripts/{script_path}`: Serves the content of internal SQL scripts.\r\n    *   `redshift://schemas`: Lists user-defined schemas.\r\n    *   `redshift://wlm/configuration`: Retrieves WLM configuration details.\r\n    *   `redshift://schema/{schema_name}/tables`: Lists tables within a specified schema.\r\n\r\n## üöÄ Usage\r\n\r\n- **Configure Environment Variables:** Set the required variables for connecting via Redshift Data API. See the **Configuration** section in the `README.md` for details. Essential variables are:\r\n    *   `REDSHIFT_CLUSTER_ID`\r\n    *   `REDSHIFT_DATABASE`\r\n    *   `REDSHIFT_SECRET_ARN`\r\n    *   `AWS_REGION` (or `AWS_DEFAULT_REGION`)\r\n    *   (Optional) `AWS_PROFILE`\r\n\r\n- Connect using your preferred MCP client (e.g., Claude Desktop, Cursor IDE) by configuring it to launch the server via `stdio`. See the **MCP Integration** section in the `README.md`.\r\n\r\n## ‚ö†Ô∏è Known Issues / Limitations\r\n\r\n*   **Handler Output Format:** Most tool handlers currently return raw results (lists of dictionaries from SQL queries) or Python Exception objects directly within the results dictionary when errors occur during script execution. User-facing formatting or summarization is minimal within the handlers themselves.\r\n*   **Limited Resource Discovery:** Only basic schema, table listing, and WLM config resources are implemented. No resources for views, functions, detailed column info, etc.\r\n*   **Read-Only Focus:** Designed primarily for diagnostics and read operations. No built-in tools for `INSERT`, `UPDATE`, `DELETE`. The `handle_execute_ad_hoc_query` tool could potentially execute write operations if the configured user has sufficient permissions, use with caution.\r\n*   **SQL Script Dependency:** Relies on the bundled SQL scripts. Errors in these scripts or changes in Redshift system views they query could affect functionality.\r\n\r\nWe hope you find this initial release useful! Please report bugs or suggest features via GitHub Issues.\r\n```",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.3.1",
        "commit_sha": "2e1e445762943b0a5d2a76f94742de058754a74c"
      },
      {
        "name": "v0.3.0",
        "commit_sha": "bff1c3347a01983364b0d9ff3dcdda8965a747dd"
      }
    ],
    "latest_version": "v0.3.1"
  },
  "readme": "# Redshift Utils MCP Server\n<div align=\"center\">\n  <!-- Container for side-by-side images -->\n  <div style=\"display: flex; justify-content: center; align-items: center; gap: 20px;\">\n    <img src=\"docs/banner.png\" width=\"320\">\n    \n <a href=\"https://glama.ai/mcp/servers/@vinodismyname/redshift-utils-mcp\">\n      <img width=\"400\" src=\"https://glama.ai/mcp/servers/@vinodismyname/redshift-utils-mcp/badge\" alt=\"redshift-utils-mcp MCP server\" />\n  </div>\n  \n  <!-- Stats in a clean format -->\n  <p>\n    <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License\">\n    <img src=\"https://img.shields.io/badge/Language-Python-blue.svg\" alt=\"Python\">\n  </p>\n</div>\n\n## Overview\n\nThis project implements a Model Context Protocol (MCP) server designed specifically to interact with Amazon Redshift databases.\n\nIt bridges the gap between Large Language Models (LLMs) or AI assistants (like those in Claude, Cursor, or custom applications) and your Redshift data warehouse, enabling secure, standardized data access and interaction. This allows users to query data, understand database structure, and monitoring/diagnostic operations using natural language or AI-driven prompts.\n\nThis server is for developers, data analysts, or teams looking to integrate LLM capabilities directly with their Amazon Redshift data environment in a structured and secure manner.\n\n## Table of Contents\n\n- [Redshift Utils MCP Server](#redshift-utils-mcp-server)\n  - [Overview](#overview)\n  - [Table of Contents](#table-of-contents)\n  - [Features](#features)\n  - [Prerequisites](#prerequisites)\n  - [Configuration](#configuration)\n  - [Usage](#usage)\n    - [Connecting with Claude Desktop / Anthropic Console:](#connecting-with-claude-desktop--anthropic-console)\n    - [Connecting with Cursor IDE:](#connecting-with-cursor-ide)\n    - [Available MCP Resources](#available-mcp-resources)\n    - [Available MCP Tools](#available-mcp-tools)\n  - [TO DO](#to-do)\n  - [Contributing](#contributing)\n  - [License](#license)\n  - [References](#references)\n\n## Features\n\n*   ‚ú® **Secure Redshift Connection (via Data API):** Connects to your Amazon Redshift cluster using the AWS Redshift Data API via Boto3, leveraging AWS Secrets Manager for credentials managed securely via environment variables.\n*   üîç **Schema Discovery:** Exposes MCP resources for listing schemas and tables within a specified schema.\n*   üìä **Metadata & Statistics:** Provides a tool (`handle_inspect_table`) to gather detailed table metadata, statistics (like size, row counts, skew, stats staleness), and maintenance status.\n*   üìù **Read-Only Query Execution:** Offers a secure MCP tool (`handle_execute_ad_hoc_query`) to execute arbitrary SELECT queries against the Redshift database, enabling data retrieval based on LLM requests.\n*   üìà **Query Performance Analysis:** Includes a tool (`handle_diagnose_query_performance`) to retrieve and analyze the execution plan, metrics, and historical data for a specific query ID.\n*   üîç **Table Inspection:** Provides a tool (`handle_inspect_table`) to perform a comprehensive inspection of a table, including design, storage, health, and usage.\n*   ü©∫ **Cluster Health Check:** Offers a tool (`handle_check_cluster_health`) to perform a basic or full health assessment of the cluster using various diagnostic queries.\n*   üîí **Lock Diagnosis:** Provides a tool (`handle_diagnose_locks`) to identify and report on current lock contention and blocking sessions.\n*   üìä **Workload Monitoring:** Includes a tool (`handle_monitor_workload`) to analyze cluster workload patterns over a time window, covering WLM, top queries, and resource usage.\n*   üìù **DDL Retrieval:** Offers a tool (`handle_get_table_definition`) to retrieve the `SHOW TABLE` output (DDL) for a specified table.\n*   üõ°Ô∏è **Input Sanitization:** Utilizes parameterized queries via the Boto3 Redshift Data API client where applicable to mitigate SQL injection risks.\n*   üß© **Standardized MCP Interface:** Adheres to the Model Context Protocol specification for seamless integration with compatible clients (e.g., Claude Desktop, Cursor IDE, custom applications).\n\n## Prerequisites\n\nSoftware:\n*   Python 3.8+\n*   `uv` (recommended package manager)\n*   Git (for cloning the repository)\n\nInfrastructure & Access:\n\n*   Access to an Amazon Redshift cluster.\n*   An AWS account with permissions to use the Redshift Data API (`redshift-data:*`) and access the specified Secrets Manager secret (`secretsmanager:GetSecretValue`).\n*   A Redshift user account whose credentials are stored in AWS Secrets Manager. This user needs the necessary permissions within Redshift to perform the actions enabled by this server (e.g., `CONNECT` to the database, `SELECT` on target tables, `SELECT` on relevant system views like `pg_class`, `pg_namespace`, `svv_all_schemas`, `svv_tables`, `svv_table_info``). Using a role with the principle of least privilege is strongly recommended. See [Security Considerations](#security-considerations).\n\nCredentials:\n\nYour Redshift connection details are managed via AWS Secrets Manager, and the server connects using the Redshift Data API. You need:\n\n*   The Redshift cluster identifier.\n*   The database name within the cluster.\n*   The ARN of the AWS Secrets Manager secret containing the database credentials (username and password).\n*   The AWS region where the cluster and secret reside.\n*   Optionally, an AWS profile name if not using default credentials/region.\n\nThese details will be configured via environment variables as detailed in the [Configuration](#configuration) section.\n\n## Configuration\n\nSet Environment Variables:\nThis server requires the following environment variables to connect to your Redshift cluster via the AWS Data API. You can set these directly in your shell, using a systemd service file, a Docker environment file, or by creating a `.env` file in the project's root directory (if using a tool like `uv` or `python-dotenv` that supports loading from `.env`).\n\nExample using shell export:\n```bash\nexport REDSHIFT_CLUSTER_ID=\"your-cluster-id\"\nexport REDSHIFT_DATABASE=\"your_database_name\"\nexport REDSHIFT_SECRET_ARN=\"arn:aws:secretsmanager:us-east-1:123456789012:secret:your-redshift-secret-XXXXXX\"\nexport AWS_REGION=\"us-east-1\" # Or AWS_DEFAULT_REGION\n# export AWS_PROFILE=\"your-aws-profile-name\" # Optional\n```\n\nExample `.env` file (see `.env.example`):\n```dotenv\n# .env file for Redshift MCP Server configuration\n# Ensure this file is NOT committed to version control if it contains secrets. Add it to .gitignore.\n\nREDSHIFT_CLUSTER_ID=\"your-cluster-id\"\nREDSHIFT_DATABASE=\"your_database_name\"\nREDSHIFT_SECRET_ARN=\"arn:aws:secretsmanager:us-east-1:123456789012:secret:your-redshift-secret-XXXXXX\"\nAWS_REGION=\"us-east-1\" # Or AWS_DEFAULT_REGION\n# AWS_PROFILE=\"your-aws-profile-name\" # Optional\n```\n\nRequired Variables Table:\n\n| Variable Name         | Required | Description                                                      | Example Value                                                          |\n| :-------------------- | :------- | :--------------------------------------------------------------- | :----------------------------------------------------------------------- |\n| `REDSHIFT_CLUSTER_ID` | Yes      | Your Redshift cluster identifier.                                | `my-redshift-cluster`                                                  |\n| `REDSHIFT_DATABASE`   | Yes      | The name of the database to connect to.                          | `mydatabase`                                                           |\n| `REDSHIFT_SECRET_ARN` | Yes      | AWS Secrets Manager ARN for Redshift credentials.                | `arn:aws:secretsmanager:us-east-1:123456789012:secret:mysecret-abcdef` |\n| `AWS_REGION`          | Yes      | AWS region for Data API and Secrets Manager.                     | `us-east-1`                                                            |\n| `AWS_DEFAULT_REGION`  | No       | Alternative to `AWS_REGION` for specifying the AWS region.       | `us-west-2`                                                            |\n| `AWS_PROFILE`         | No       | AWS profile name to use from your credentials file (~/.aws/...). | `my-redshift-profile`                                                  |\n\n*Note: Ensure the AWS credentials used by Boto3 (via environment, profile, or IAM role) have permissions to access the specified `REDSHIFT_SECRET_ARN` and use the Redshift Data API (`redshift-data:*`).*\n\n## Usage\n\n### Connecting with Claude Desktop / Anthropic Console:\nAdd the following configuration block to your `mcp.json` file. Adjust `command`, `args`, `env`, and `workingDirectory` based on your installation method and setup.\n\n```json\n{\n  \"mcpServers\": {\n    \"redshift-utils-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"redshift_utils_mcp\"],\n      \"env\": {\n        \"REDSHIFT_CLUSTER_ID\":\"your-cluster-id\",\n        \"REDSHIFT_DATABASE\":\"your_database_name\",\n        \"REDSHIFT_SECRET_ARN\":\"arn:aws:secretsmanager:...\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n  }\n}\n```\n\n### Connecting with Cursor IDE:\n1.  Start the MCP server locally using the instructions in the [Usage / Quickstart](#usage--quickstart) section.\n2.  In Cursor, open the Command Palette (Cmd/Ctrl + Shift + P).\n3.  Type \"Connect to MCP Server\" or navigate to the MCP settings.\n4.  Add a new server connection.\n5.  Choose the `stdio` transport type.\n6.  Enter the command and arguments required to start your server (`uvx run redshift_utils_mcp`). Ensure any necessary environment variables are available to the command being run.\n7.  Cursor should detect the server and its available tools/resources.\n\n### Available MCP Resources\n\n| Resource URI Pattern                     | Description                                                                               | Example URI                       |\n| :--------------------------------------- | :---------------------------------------------------------------------------------------- | :-------------------------------- |\n| `/scripts/{script_path}`                 | Retrieves the raw content of a SQL script file from the server's `sql_scripts` directory. | `/scripts/health/disk_usage.sql`  |\n| `redshift://schemas`                     | Lists all accessible user-defined schemas in the connected database.                      | `redshift://schemas`              |\n| `redshift://wlm/configuration`           | Retrieves the current Workload Management (WLM) configuration details.                    | `redshift://wlm/configuration`    |\n| `redshift://schema/{schema_name}/tables` | Lists all accessible tables and views within the specified `{schema_name}`.               | `redshift://schema/public/tables` |\n\nReplace `{script_path}` and `{schema_name}` with the actual values when making requests.\nAccessibility of schemas/tables depends on the permissions granted to the Redshift user configured via `REDSHIFT_SECRET_ARN`.\n\n### Available MCP Tools\n\n| Tool Name                           | Description                                                                                                  | Key Parameters (Required*)                                | Example Invocation                                                                              |\n| :---------------------------------- | :----------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------- | :---------------------------------------------------------------------------------------------- |\n| `handle_check_cluster_health`       | Performs a health assessment of the Redshift cluster using a set of diagnostic SQL scripts.                  | `level` (optional), `time_window_days` (optional)         | `use_mcp_tool(\"redshift-admin\", \"handle_check_cluster_health\", {\"level\": \"full\"})`              |\n| `handle_diagnose_locks`             | Identifies active lock contention and blocking sessions in the cluster.                                      | `min_wait_seconds` (optional)                             | `use_mcp_tool(\"redshift-admin\", \"handle_diagnose_locks\", {\"min_wait_seconds\": 10})`             |\n| `handle_diagnose_query_performance` | Analyzes a specific query's execution performance, including plan, metrics, and historical data.             | `query_id`*                                               | `use_mcp_tool(\"redshift-admin\", \"handle_diagnose_query_performance\", {\"query_id\": 12345})`      |\n| `handle_execute_ad_hoc_query`       | Executes an arbitrary SQL query provided by the user via Redshift Data API. Designed as an escape hatch.     | `sql_query`*                                              | `use_mcp_tool(\"redshift-admin\", \"handle_execute_ad_hoc_query\", {\"sql_query\": \"SELECT ...\"})`    |\n| `handle_get_table_definition`       | Retrieves the DDL (Data Definition Language) statement (`SHOW TABLE`) for a specific table.                  | `schema_name`*, `table_name`*                             | `use_mcp_tool(\"redshift-admin\", \"handle_get_table_definition\", {\"schema_name\": \"public\", ...})` |\n| `handle_inspect_table`              | Retrieves detailed information about a specific Redshift table, covering design, storage, health, and usage. | `schema_name`*, `table_name`*                             | `use_mcp_tool(\"redshift-admin\", \"handle_inspect_table\", {\"schema_name\": \"analytics\", ...})`     |\n| `handle_monitor_workload`           | Analyzes cluster workload patterns over a specified time window using various diagnostic scripts.            | `time_window_days` (optional), `top_n_queries` (optional) | `use_mcp_tool(\"redshift-admin\", \"handle_monitor_workload\", {\"time_window_days\": 7})`            |\n\n## TO DO\n- [ ] Improve Prompt Options\n- [ ] Add support for more credential methods\n- [ ] Add Support for Redshift Serverless\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines.\n\nFind/Report Issues: Check the GitHub Issues page for existing bugs or feature requests. Feel free to open a new issue if needed.\n\nSecurity is critical when providing database access via an MCP server. Please consider the following:\n\nüîí **Credentials Management:** This server uses AWS Secrets Manager via the Redshift Data API, which is a more secure approach than storing credentials directly in environment variables or configuration files. Ensure your AWS credentials used by Boto3 (via environment, profile, or IAM role) are managed securely and have the minimum necessary permissions. Never commit your AWS credentials or `.env` files containing secrets to version control.\n\nüõ°Ô∏è **Principle of Least Privilege:** Configure the Redshift user whose credentials are in AWS Secrets Manager with the minimum permissions required for the server's intended functionality. For example, if only read access is needed, grant only `CONNECT` and `SELECT` privileges on the necessary schemas/tables and `SELECT` on the required system views. Avoid using highly privileged users like `admin` or the cluster superuser.\n\nFor guidance on creating restricted Redshift users and managing permissions, refer to the official (https://docs.aws.amazon.com/redshift/latest/mgmt/security.html).\n\n## License\n\nThis project is licensed under the MIT License. See the (LICENSE) file for details.\n\n## References\n\n*   This project relies heavily on the [Model Context Protocol specification](https://modelcontextprotocol.io/specification/).\n*   Built using the official MCP SDK provided by [Model Context Protocol](https://modelcontextprotocol.io/).\n*   Utilizes the AWS SDK for Python ([Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) to interact with the [Amazon Redshift Data API](https://docs.aws.amazon.com/redshift-data/latest/APIReference/Welcome.html).\n*   Many of the diagnostic SQL scripts are adapted from the excellent [awslabs/amazon-redshift-utils](https://github.com/awslabs/amazon-redshift-utils) repository.\n"
}