{
  "mcp_name": "Atla",
  "mcp_description": "Enable AI agents to interact with the [Atla API](https://docs.atla-ai.com/) for state-of-the-art LLMJ evaluation.",
  "mcp_id": "atla-ai_atla-mcp-server",
  "fetch_timestamp": "2025-06-23T01:20:14.154997Z",
  "github_url": "https://github.com/atla-ai/atla-mcp-server",
  "repository": {
    "name": "atla-mcp-server",
    "full_name": "atla-ai/atla-mcp-server",
    "description": "An MCP server implementation providing a standardized interface for LLMs to interact with the Atla API.",
    "html_url": "https://github.com/atla-ai/atla-mcp-server",
    "created_at": "2025-04-09T09:55:33Z",
    "updated_at": "2025-05-28T03:48:16Z",
    "pushed_at": "2025-04-22T20:28:20Z",
    "size": 41,
    "stargazers_count": 14,
    "watchers_count": 14,
    "forks_count": 1,
    "open_issues_count": 1,
    "language": "Python",
    "license": "MIT License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "atla-ai",
      "type": "Organization",
      "avatar_url": "https://avatars.githubusercontent.com/u/145455090?v=4",
      "html_url": "https://github.com/atla-ai"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 1,
    "subscribers_count": 2,
    "languages": {
      "Python": 11730
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 20,
    "contributors_count": 5,
    "latest_release": {
      "tag_name": "v0.1.2",
      "name": "v0.1.2",
      "published_at": "2025-04-22T17:00:53Z",
      "body": "## What's Changed\r\n* [Fix] Remove breaking `src` folder by @TobyDrane in https://github.com/atla-ai/atla-mcp-server/pull/19\r\n\r\n\r\n**Full Changelog**: https://github.com/atla-ai/atla-mcp-server/compare/v0.1.1...v0.1.2",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.1.2",
        "commit_sha": "795541c30837f7feb330928fce1b98c75113a15e"
      },
      {
        "name": "v0.1.1",
        "commit_sha": "a18046b61f7c1860cfd4dd2674253bd6d3f9b513"
      }
    ],
    "latest_version": "v0.1.2"
  },
  "readme": "# Atla MCP Server\n\nAn MCP server implementation providing a standardized interface for LLMs to interact with the Atla API for state-of-the-art LLMJ evaluation.\n\n> Learn more about Atla [here](https://docs.atla-ai.com). Learn more about the Model Context Protocol [here](https://modelcontextprotocol.io).\n\n<a href=\"https://glama.ai/mcp/servers/@atla-ai/atla-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@atla-ai/atla-mcp-server/badge\" alt=\"Atla MCP server\" />\n</a>\n\n## Available Tools\n\n- `evaluate_llm_response`: Evaluate an LLM's response to a prompt using a given evaluation criteria. This function uses an Atla evaluation model under the hood to return a dictionary containing a score for the model's response and a textual critique containing feedback on the model's response.\n- `evaluate_llm_response_on_multiple_criteria`: Evaluate an LLM's response to a prompt across _multiple_ evaluation criteria. This function uses an Atla evaluation model under the hood to return a list of dictionaries, each containing an evaluation score and critique for a given criteria.\n\n## Usage\n\n> To use the MCP server, you will need an Atla API key. You can find your existing API key [here](https://www.atla-ai.com/sign-in) or create a new one [here](https://www.atla-ai.com/sign-up).\n\n### Installation\n\n> We recommend using `uv` to manage the Python environment. See [here](https://docs.astral.sh/uv/getting-started/installation/) for installation instructions.\n\n### Manually running the server\n\nOnce you have `uv` installed and have your Atla API key, you can manually run the MCP server using `uvx` (which is provided by `uv`):\n\n```bash\nATLA_API_KEY=<your-api-key> uvx atla-mcp-server\n```\n\n### Connecting to the server\n\n> Having issues or need help connecting to another client? Feel free to open an issue or [contact us](mailto:support@atla-ai.com)!\n\n#### OpenAI Agents SDK\n\n> For more details on using the OpenAI Agents SDK with MCP servers, refer to the [official documentation](https://openai.github.io/openai-agents-python/).\n\n1. Install the OpenAI Agents SDK:\n\n```shell\npip install openai-agents\n```\n\n2. Use the OpenAI Agents SDK to connect to the server:\n\n```python\nimport os\n\nfrom agents import Agent\nfrom agents.mcp import MCPServerStdio\n\nasync with MCPServerStdio(\n        params={\n            \"command\": \"uvx\",\n            \"args\": [\"atla-mcp-server\"],\n            \"env\": {\"ATLA_API_KEY\": os.environ.get(\"ATLA_API_KEY\")}\n        }\n    ) as atla_mcp_server:\n    ...\n```\n\n#### Claude Desktop\n\n> For more details on configuring MCP servers in Claude Desktop, refer to the [official MCP quickstart guide](https://modelcontextprotocol.io/quickstart/user).\n\n1. Add the following to your `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"atla-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"atla-mcp-server\"],\n      \"env\": {\n        \"ATLA_API_KEY\": \"<your-atla-api-key>\"\n      }\n    }\n  }\n}\n```\n\n2. **Restart Claude Desktop** to apply the changes.\n\nYou should now see options from `atla-mcp-server` in the list of available MCP tools.\n\n#### Cursor\n\n> For more details on configuring MCP servers in Cursor, refer to the [official documentation](https://docs.cursor.com/context/model-context-protocol).\n\n1. Add the following to your `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"atla-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"atla-mcp-server\"],\n      \"env\": {\n        \"ATLA_API_KEY\": \"<your-atla-api-key>\"\n      }\n    }\n  }\n}\n```\n\nYou should now see `atla-mcp-server` in the list of available MCP servers.\n\n## Contributing\n\nContributions are welcome! Please see the [CONTRIBUTING.md](CONTRIBUTING.md) file for details.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n"
}