{
  "mcp_name": "NON906/omniparser-autogui-mcp",
  "mcp_description": "üêç Automatic operation of on-screen GUI.",
  "mcp_id": "NON906_omniparser-autogui-mcp",
  "fetch_timestamp": "2025-06-23T07:09:26.747478Z",
  "github_url": "https://github.com/NON906/omniparser-autogui-mcp",
  "repository": {
    "name": "omniparser-autogui-mcp",
    "full_name": "NON906/omniparser-autogui-mcp",
    "description": "Automatic operation of on-screen GUI.",
    "html_url": "https://github.com/NON906/omniparser-autogui-mcp",
    "created_at": "2025-02-26T06:38:10Z",
    "updated_at": "2025-06-17T01:56:49Z",
    "pushed_at": "2025-03-02T01:53:48Z",
    "size": 178,
    "stargazers_count": 44,
    "watchers_count": 44,
    "forks_count": 7,
    "open_issues_count": 1,
    "language": "Python",
    "license": "MIT License",
    "topics": [],
    "default_branch": "master",
    "owner": {
      "login": "NON906",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/30926385?v=4",
      "html_url": "https://github.com/NON906"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 7,
    "subscribers_count": 4,
    "languages": {
      "Python": 23807
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 0,
    "contributors_count": 1
  },
  "readme": "# omniparser-autogui-mcp\n\nÔºà[Êó•Êú¨Ë™ûÁâà„ÅØ„Åì„Å°„Çâ](README_ja.md)Ôºâ\n\nThis is an [MCP server](https://modelcontextprotocol.io/introduction) that analyzes the screen with [OmniParser](https://github.com/microsoft/OmniParser) and automatically operates the GUI.  \nConfirmed on Windows.\n\n## License notes\n\nThis is MIT license, but Excluding submodules and sub packages.  \nOmniParser's repository is CC-BY-4.0.  \nEach OmniParser model has a different license ([reference](https://github.com/microsoft/OmniParser?tab=readme-ov-file#model-weights-license)).\n\n## Installation\n\n1. Please do the following:\n\n```\ngit clone --recursive https://github.com/NON906/omniparser-autogui-mcp.git\ncd omniparser-autogui-mcp\nuv sync\nset OCR_LANG=en\nuv run download_models.py\n```\n\n(Other than Windows, use ``export`` instead of ``set``.)  \n(If you want ``langchain_example.py`` to work, ``uv sync --extra langchain`` instead.)\n\n2. Add this to your ``claude_desktop_config.json``:\n\n```claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"omniparser_autogui_mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp\",\n        \"run\",\n        \"omniparser-autogui-mcp\"\n      ],\n      \"env\": {\n        \"PYTHONIOENCODING\": \"utf-8\",\n        \"OCR_LANG\": \"en\"\n      }\n    }\n  }\n}\n```\n\n(Replace ``D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp`` with the directory you cloned.)\n\n``env`` allows for the following additional configurations:\n\n- ``OMNI_PARSER_BACKEND_LOAD``  \nIf it does not work with other clients (such as [LibreChat](https://github.com/danny-avila/LibreChat)), specify ``1``.\n\n- ``TARGET_WINDOW_NAME``  \nIf you want to specify the window to operate, please specify the window name.  \nIf not specified, operates on the entire screen.\n\n- ``OMNI_PARSER_SERVER``  \nIf you want OmniParser processing to be done on another device, specify the server's address and port, such as ``127.0.0.1:8000``.  \nThe server can be started with ``uv run omniparserserver``.\n\n- ``SSE_HOST``, ``SSE_PORT``  \nIf specified, communication will be done via SSE instead of stdio.\n\n- ``SOM_MODEL_PATH``, ``CAPTION_MODEL_NAME``, ``CAPTION_MODEL_PATH``, ``OMNI_PARSER_DEVICE``, ``BOX_TRESHOLD``  \nThese are for OmniParser configuration.  \nUsually, they are not necessary.\n\n## Usage Examples\n\n- Search for \"MCP server\" in the on-screen browser.\n\netc."
}