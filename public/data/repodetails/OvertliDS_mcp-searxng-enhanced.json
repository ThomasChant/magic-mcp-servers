{
  "mcp_name": "MCP-SearXNG-Enhanced Web Search",
  "mcp_description": "An enhanced MCP server for SearXNG web searching, utilizing a category-aware web-search, web-scraping, and includes a date/time retrieval tool.",
  "mcp_id": "OvertliDS_mcp-searxng-enhanced",
  "fetch_timestamp": "2025-06-23T06:35:56.146613Z",
  "github_url": "https://github.com/OvertliDS/mcp-searxng-enhanced",
  "repository": {
    "name": "mcp-searxng-enhanced",
    "full_name": "OvertliDS/mcp-searxng-enhanced",
    "description": "Enhanced MCP server for SearXNG: category-aware web-search, web-scraping, and date/time retrieval.",
    "html_url": "https://github.com/OvertliDS/mcp-searxng-enhanced",
    "created_at": "2025-05-10T00:20:37Z",
    "updated_at": "2025-06-19T04:53:57Z",
    "pushed_at": "2025-05-10T01:04:52Z",
    "size": 21,
    "stargazers_count": 4,
    "watchers_count": 4,
    "forks_count": 2,
    "open_issues_count": 1,
    "language": "Python",
    "license": "MIT License",
    "topics": [
      "citations",
      "datetime",
      "docker",
      "docker-image",
      "mcp",
      "mcp-server",
      "open-source",
      "python",
      "research-tool",
      "searxng",
      "searxng-mcp",
      "webscraper",
      "websearch",
      "websearch-agent"
    ],
    "default_branch": "master",
    "owner": {
      "login": "OvertliDS",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/188361908?v=4",
      "html_url": "https://github.com/OvertliDS"
    },
    "has_issues": true,
    "has_projects": false,
    "has_downloads": true,
    "has_wiki": false,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 2,
    "subscribers_count": 1,
    "languages": {
      "Python": 52014,
      "PowerShell": 1615,
      "Shell": 1440,
      "Batchfile": 1431,
      "Dockerfile": 1282
    },
    "language_percentages": {
      "Python": 90.02,
      "PowerShell": 2.79,
      "Shell": 2.49,
      "Batchfile": 2.48,
      "Dockerfile": 2.22
    },
    "pull_requests_count": 1,
    "contributors_count": 1,
    "tags": [
      {
        "name": "v1.0.0",
        "commit_sha": "51e9666c0cc046980cfe350f159a2c4adf19dff6"
      }
    ],
    "latest_version": "v1.0.0"
  },
  "readme": "# MCP SearXNG Enhanced Server\n\nA Model Context Protocol (MCP) server for category-aware web search, website scraping, and date/time tools. Designed for seamless integration with SearXNG and modern MCP clients.\n\n## Features\n\n- üîç SearXNG-powered web search with category support (general, images, videos, files, map, social media)\n- üìÑ Website content scraping with citation metadata and automatic Reddit URL conversion\n- üíæ In-memory caching with automatic freshness validation\n- üö¶ Domain-based rate limiting to prevent service abuse\n- üïí Timezone-aware date/time tool\n- ‚ö†Ô∏è Robust error handling with custom exception types\n- üê≥ Dockerized and configurable via environment variables\n- ‚öôÔ∏è Configuration persistence between container restarts\n\n## Quick Start\n\n### Prerequisites\n\n- Docker installed on your system\n- A running SearXNG instance (self-hosted or accessible endpoint)\n\n### Installation & Usage\n\n**Build the Docker image:**\n```bash\ndocker build -t overtlids/mcp-searxng-enhanced:latest .\n```\n\n**Run with your SearXNG instance (Manual Docker Run):**\n```bash\ndocker run -i --rm --network=host \\\n  -e SEARXNG_ENGINE_API_BASE_URL=\"http://127.0.0.1:8080/search\" \\\n  -e DESIRED_TIMEZONE=\"America/New_York\" \\\n  overtlids/mcp-searxng-enhanced:latest\n```\nIn this example, `SEARXNG_ENGINE_API_BASE_URL` is explicitly set. `DESIRED_TIMEZONE` is also explicitly set to `America/New_York`, which matches its default value. If an environment variable is not provided using an `-e` flag during the `docker run` command, the server will automatically use the default value defined in its `Dockerfile` (refer to the Environment Variables table below). Thus, if you intend to use the default for `DESIRED_TIMEZONE`, you could omit the `-e DESIRED_TIMEZONE=\"America/New_York\"` flag. However, `SEARXNG_ENGINE_API_BASE_URL` is critical and usually needs to be set to match your specific SearXNG instance's address if the Dockerfile default (`http://host.docker.internal:8080/search`) is not appropriate.\n\n**Note on Manual Docker Run:** This command runs the Docker container independently. If you are using an MCP client (like Cline in VS Code) to manage this server, the client will start its own instance of the container using the settings defined in *its own configuration*. For the MCP client to use specific environment variables, they **must** be configured within the client's settings for this server (see below).\n\n**Configure your MCP client** (e.g., Cline in VS Code):\n\nFor your MCP client to correctly manage and run this server, you **must** define all necessary environment variables within the client's settings for the `overtlids/mcp-searxng-enhanced` server. The MCP client will use these settings to construct the `docker run` command.\n\nThe following is the **recommended default configuration** for this server within your MCP client's JSON settings (e.g., `cline_mcp_settings.json`). This example explicitly lists all environment variables set to their default values as defined in the `Dockerfile`. You can copy and paste this directly and then customize any values as needed.\n\n```json\n{\n  \"mcpServers\": {\n    \"overtlids/mcp-searxng-enhanced\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\", \"--network=host\",\n        \"-e\", \"SEARXNG_ENGINE_API_BASE_URL=http://host.docker.internal:8080/search\",\n        \"-e\", \"DESIRED_TIMEZONE=America/New_York\",\n        \"-e\", \"ODS_CONFIG_PATH=/config/ods_config.json\",\n        \"-e\", \"RETURNED_SCRAPPED_PAGES_NO=3\",\n        \"-e\", \"SCRAPPED_PAGES_NO=5\",\n        \"-e\", \"PAGE_CONTENT_WORDS_LIMIT=5000\",\n        \"-e\", \"CITATION_LINKS=True\",\n        \"-e\", \"MAX_IMAGE_RESULTS=10\",\n        \"-e\", \"MAX_VIDEO_RESULTS=10\",\n        \"-e\", \"MAX_FILE_RESULTS=5\",\n        \"-e\", \"MAX_MAP_RESULTS=5\",\n        \"-e\", \"MAX_SOCIAL_RESULTS=5\",\n        \"-e\", \"TRAFILATURA_TIMEOUT=15\",\n        \"-e\", \"SCRAPING_TIMEOUT=20\",\n        \"-e\", \"CACHE_MAXSIZE=100\",\n        \"-e\", \"CACHE_TTL_MINUTES=5\",\n        \"-e\", \"CACHE_MAX_AGE_MINUTES=30\",\n        \"-e\", \"RATE_LIMIT_REQUESTS_PER_MINUTE=10\",\n        \"-e\", \"RATE_LIMIT_TIMEOUT_SECONDS=60\",\n        \"-e\", \"IGNORED_WEBSITES=\",\n        \"overtlids/mcp-searxng-enhanced:latest\"\n      ],\n      \"timeout\": 60\n    }\n  }\n}\n```\n**Key Points for MCP Client Configuration:**\n- The example above provides a complete set of arguments to run the Docker container with all environment variables set to their default values.\n- To customize any setting, simply modify the value for the corresponding `-e \"VARIABLE_NAME=value\"` line within the `args` array in your MCP client's configuration. For instance, to change `SEARXNG_ENGINE_API_BASE_URL` and `DESIRED_TIMEZONE`, you would adjust their respective lines.\n- Refer to the \"Environment Variables\" table below for a detailed description of each variable and its default.\n- The server's behavior is primarily controlled by these environment variables. While an `ods_config.json` file can also influence settings (see Configuration Management), environment variables passed by the MCP client take precedence.\n\n## Running Natively (Without Docker)\n\nIf you prefer to run the server directly using Python without Docker, follow these steps:\n\n**1. Python Installation:**\n   - This server requires **Python 3.9 or newer**. Python 3.11 (as used in the Docker image) is recommended.\n   - You can download Python from [python.org](https://www.python.org/downloads/).\n\n**2. Clone the Repository:**\n   - Get the code from GitHub:\n     ```bash\n     git clone https://github.com/OvertliDS/mcp-searxng-enhanced.git\n     cd mcp-searxng-enhanced\n     ```\n\n**3. Create and Activate a Virtual Environment (Recommended):**\n   - Using a virtual environment helps manage dependencies and avoid conflicts with other Python projects.\n     ```bash\n     # For Linux/macOS\n     python3 -m venv .venv\n     source .venv/bin/activate\n\n     # For Windows (Command Prompt)\n     python -m venv .venv\n     .\\.venv\\Scripts\\activate.bat\n\n     # For Windows (PowerShell)\n     python -m venv .venv\n     .\\.venv\\Scripts\\Activate.ps1\n     ```\n\n**4. Install Dependencies:**\n   - Install the required Python packages:\n     ```bash\n     pip install -r requirements.txt\n     ```\n     Key dependencies include `httpx`, `BeautifulSoup4`, `pydantic`, `trafilatura`, `python-dateutil`, `cachetools`, and `zoneinfo`.\n\n**5. Ensure SearXNG is Accessible:**\n   - You still need a running SearXNG instance. Make sure you have its API base URL (e.g., `http://127.0.0.1:8080/search`).\n\n**6. Set Environment Variables:**\n   - The server is configured via environment variables. At a minimum, you'll likely need to set `SEARXNG_ENGINE_API_BASE_URL`.\n   - **Linux/macOS (bash/zsh):**\n     ```bash\n     export SEARXNG_ENGINE_API_BASE_URL=\"http://your-searxng-instance:port/search\"\n     export DESIRED_TIMEZONE=\"America/Los_Angeles\"\n     ```\n   - **Windows (Command Prompt):**\n     ```bash\n     set SEARXNG_ENGINE_API_BASE_URL=\"http://your-searxng-instance:port/search\"\n     set DESIRED_TIMEZONE=\"America/Los_Angeles\"\n     ```\n   - **Windows (PowerShell):**\n     ```bash\n     $env:SEARXNG_ENGINE_API_BASE_URL=\"http://your-searxng-instance:port/search\"\n     $env:DESIRED_TIMEZONE=\"America/Los_Angeles\"\n     ```\n   - Refer to the \"Environment Variables\" table below for all available options. If not set, defaults from the script or an `ods_config.json` file (if present in the root directory or at `ODS_CONFIG_PATH`) will be used.\n\n**7. Run the Server:**\n   - Execute the Python script:\n     ```bash\n     python mcp_server.py\n     ```\n   - The server will start and listen for MCP client connections via stdin/stdout.\n\n**8. Configuration File (`ods_config.json`):**\n   - Alternatively, or in combination with environment variables, you can create an `ods_config.json` file in the project's root directory (or the path specified by the `ODS_CONFIG_PATH` environment variable). Environment variables will always take precedence over values in this file. Example:\n    ```json\n    {\n      \"searxng_engine_api_base_url\": \"http://127.0.0.1:8080/search\",\n      \"desired_timezone\": \"America/New_York\"\n    }\n    ```\n\n## Environment Variables\n\nThe following environment variables control the server's behavior. You can set them in your MCP client's configuration (recommended for client-managed servers) or when running Docker manually.\n\n| Variable                        | Description                                | Default (from Dockerfile)         | Notes                                                                                                |\n|---------------------------------|--------------------------------------------|-----------------------------------|------------------------------------------------------------------------------------------------------|\n| `SEARXNG_ENGINE_API_BASE_URL`   | SearXNG search endpoint                    | `http://host.docker.internal:8080/search` | **Crucial for server operation**                                                                     |\n| `DESIRED_TIMEZONE`              | Timezone for date/time tool                | `America/New_York`                | E.g., `America/Los_Angeles`. List of tz database time zones: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones |\n| `ODS_CONFIG_PATH`               | Path to persistent configuration file      | `/config/ods_config.json`         | Typically left as default within the container.     |\n| `RETURNED_SCRAPPED_PAGES_NO`    | Max pages to return per search             | `3`                               |                                                       |\n| `SCRAPPED_PAGES_NO`             | Max pages to attempt scraping              | `5`                               |                                                       |\n| `PAGE_CONTENT_WORDS_LIMIT`      | Max words per scraped page                 | `5000`                            |                                                       |\n| `CITATION_LINKS`                | Enable/disable citation events             | `True`                            | `True` or `False`                                     |\n| `MAX_IMAGE_RESULTS`             | Maximum image results to return            | `10`                              |                                                       |\n| `MAX_VIDEO_RESULTS`             | Maximum video results to return            | `10`                              |                                                       |\n| `MAX_FILE_RESULTS`              | Maximum file results to return             | `5`                               |                                                       |\n| `MAX_MAP_RESULTS`               | Maximum map results to return              | `5`                               |                                                       |\n| `MAX_SOCIAL_RESULTS`            | Maximum social media results to return     | `5`                               |                                                       |\n| `TRAFILATURA_TIMEOUT`           | Content extraction timeout (seconds)       | `15`                              |                                                       |\n| `SCRAPING_TIMEOUT`              | HTTP request timeout (seconds)             | `20`                              |                                                       |\n| `CACHE_MAXSIZE`                 | Maximum number of cached websites          | `100`                             |                                                       |\n| `CACHE_TTL_MINUTES`             | Cache time-to-live (minutes)               | `5`                               |                                                       |\n| `CACHE_MAX_AGE_MINUTES`         | Maximum age for cached content (minutes)   | `30`                              |                                                       |\n| `RATE_LIMIT_REQUESTS_PER_MINUTE`| Max requests per domain per minute         | `10`                              |                                                       |\n| `RATE_LIMIT_TIMEOUT_SECONDS`    | Rate limit tracking window (seconds)       | `60`                              |                                                       |\n| `IGNORED_WEBSITES`              | Comma-separated list of sites to ignore    | `\"\"` (empty)                      | E.g., `\"example.com,another.org\"`                   |\n\n## Configuration Management\n\nThe server uses a three-tier configuration approach:\n\n1. **Script defaults** (hardcoded in Python)\n2. **Config file** (loaded from `ODS_CONFIG_PATH`, defaults to `/config/ods_config.json`)\n3. **Environment variables** (highest precedence)\n\nThe config file is only updated when:\n- The file doesn't exist yet (first-time initialization)\n- Environment variables are explicitly provided for the current run\n\nThis ensures that user configurations are preserved between container restarts when no new environment variables are set.\n\n## Tools & Aliases\n\n| Tool Name              | Purpose                       | Aliases                           |\n|------------------------|------------------------------ |-----------------------------------|\n| `search_web`           | Web search via SearXNG        | `search`, `web_search`, `find`, `lookup_web`, `search_online`, `access_internet`, `lookup`* |\n| `get_website`          | Scrape website content        | `fetch_url`, `scrape_page`, `get`, `load_website`, `lookup`* |\n| `get_current_datetime` | Current date/time             | `current_time`, `get_time`, `current_date` |\n\n\\*`lookup` is context-sensitive:  \n- If called with a `url` argument, it maps to `get_website`  \n- Otherwise, it maps to `search_web`\n\n### Example: Calling Tools\n\n**Web Search**\n```json\n{ \"name\": \"search_web\", \"arguments\": { \"query\": \"open source ai\" } }\n```\nor using an alias:\n```json\n{ \"name\": \"search\", \"arguments\": { \"query\": \"open source ai\" } }\n```\n\n**Category-Specific Search**\n```json\n{ \"name\": \"search_web\", \"arguments\": { \"query\": \"landscapes\", \"category\": \"images\" } }\n```\n\n**Website Scraping**\n```json\n{ \"name\": \"get_website\", \"arguments\": { \"url\": \"example.com\" } }\n```\nor using an alias:\n```json\n{ \"name\": \"lookup\", \"arguments\": { \"url\": \"example.com\" } }\n```\n\n**Current Date/Time**\n```json\n{ \"name\": \"get_current_datetime\", \"arguments\": {} }\n```\nor:\n```json\n{ \"name\": \"current_time\", \"arguments\": {} }\n```\n\n## Advanced Features\n\n### Category-Specific Search\n\nThe `search_web` tool supports different categories with tailored outputs:\n\n- **images**: Returns image URLs, titles, and source pages with optional Markdown embedding\n- **videos**: Returns video information including titles, source, and embed URLs\n- **files**: Returns downloadable file information including format and size\n- **map**: Returns location data including coordinates and addresses\n- **social media**: Returns posts and profiles from social platforms\n- **general**: Default category that scrapes and returns full webpage content\n\n### Reddit URL Conversion\n\nWhen scraping Reddit content, URLs are automatically converted to use the old.reddit.com domain for better content extraction.\n\n### Rate Limiting\n\nDomain-based rate limiting prevents excessive requests to the same domain within a time window. This prevents overwhelming target websites and potential IP blocking.\n\n### Cache Validation\n\nCached website content is automatically validated for freshness based on age. Stale content is refreshed automatically while valid cached content is served quickly.\n\n## Error Handling\n\nThe server implements a robust error handling system with these exception types:\n\n- `MCPServerError`: Base exception class for all server errors\n- `ConfigurationError`: Raised when configuration values are invalid\n- `SearXNGConnectionError`: Raised when connection to SearXNG fails\n- `WebScrapingError`: Raised when web scraping fails\n- `RateLimitExceededError`: Raised when rate limit for a domain is exceeded\n\nErrors are properly propagated to the client with informative messages.\n\n## Troubleshooting\n\n- **Cannot connect to SearXNG**: Ensure your SearXNG instance is running and the `SEARXNG_ENGINE_API_BASE_URL` environment variable points to the correct endpoint.\n- **Rate limit errors**: Adjust `RATE_LIMIT_REQUESTS_PER_MINUTE` if you're experiencing too many rate limit errors.\n- **Slow content extraction**: Increase `TRAFILATURA_TIMEOUT` to allow more time for content processing on complex pages.\n- **Docker networking issues**: If using Docker Desktop on Windows/Mac, `host.docker.internal` should resolve to the host machine. On Linux, you may need to use the host's IP address instead.\n\n## Acknowledgements\n\nInspired by:\n- [SearXNG](https://github.com/searxng/searxng) - Privacy-respecting metasearch engine\n- [Trafilatura](https://github.com/adbar/trafilatura) - Web scraping tool for text extraction\n- [ihor-sokoliuk/mcp-searxng](https://github.com/ihor-sokoliuk/mcp-searxng) - Original MCP server for SearXNG\n- [nnaoycurt](https://github.com/nnaoycurt) ([Better Web Search Tool](https://openwebui.com/t/nnaoycurt/web_search))\n- [@bwoodruff2021](https://github.com/bwoodruff2021) ([GetTimeDate Tool](https://openwebui.com/t/bwoodruff2021/gettime))\n\n## License\n\nMIT License ¬© 2025 OvertliDS\n"
}