{
  "mcp_name": "any-chat-completions-mcp",
  "mcp_description": "Chat with any other OpenAI SDK Compatible Chat Completions API, like Perplexity, Groq, xAI and more",
  "mcp_id": "pyroprompts_any-chat-completions-mcp",
  "fetch_timestamp": "2025-06-23T01:11:08.496078Z",
  "github_url": "https://github.com/pyroprompts/any-chat-completions-mcp",
  "repository": {
    "name": "any-chat-completions-mcp",
    "full_name": "pyroprompts/any-chat-completions-mcp",
    "description": "MCP Server for using any LLM as a Tool",
    "html_url": "https://github.com/pyroprompts/any-chat-completions-mcp",
    "created_at": "2024-12-02T03:40:01Z",
    "updated_at": "2025-06-21T09:41:57Z",
    "pushed_at": "2025-05-01T02:39:27Z",
    "size": 24096,
    "stargazers_count": 130,
    "watchers_count": 130,
    "forks_count": 18,
    "open_issues_count": 3,
    "language": "JavaScript",
    "license": "MIT License",
    "topics": [
      "mcp",
      "mcp-server"
    ],
    "default_branch": "main",
    "owner": {
      "login": "pyroprompts",
      "type": "Organization",
      "avatar_url": "https://avatars.githubusercontent.com/u/175894407?v=4",
      "html_url": "https://github.com/pyroprompts"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": false,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 18,
    "subscribers_count": 0,
    "languages": {
      "JavaScript": 5488,
      "Dockerfile": 1019
    },
    "language_percentages": {
      "JavaScript": 84.34,
      "Dockerfile": 15.66
    },
    "pull_requests_count": 4,
    "contributors_count": 4,
    "latest_release": {
      "tag_name": "v0.1.1",
      "name": "v0.1.1",
      "published_at": "2025-05-01T02:33:53Z",
      "body": "Changed package to `@pyroprompts/any-chat-completions-mcp`",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.1.1",
        "commit_sha": "774f5173cc2ee64907dfffc382843bbf46802835"
      },
      {
        "name": "v0.1.0",
        "commit_sha": "35b129438e01aa89195d17164a7bdcf3d0205633"
      }
    ],
    "latest_version": "v0.1.1",
    "package_json_version": "0.1.1"
  },
  "readme": "# any-chat-completions-mcp MCP Server\n\n\nIntegrate Claude with Any OpenAI SDK Compatible Chat Completion API - OpenAI, Perplexity, Groq, xAI, PyroPrompts and more.\n\nThis implements the Model Context Protocol Server. Learn more: [https://modelcontextprotocol.io](https://modelcontextprotocol.io)\n\nThis is a TypeScript-based MCP server that implements an implementation into any OpenAI SDK Compatible Chat Completions API.\n\nIt has one tool, `chat` which relays a question to a configured AI Chat Provider.\n\n\n<a href=\"https://glama.ai/mcp/servers/nuksdrfb55\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/nuksdrfb55/badge\" /></a>\n\n[![smithery badge](https://smithery.ai/badge/any-chat-completions-mcp-server)](https://smithery.ai/server/any-chat-completions-mcp-server)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo add OpenAI to Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n\nYou can use it via `npx` in your Claude Desktop configuration like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"chat-openai\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@pyroprompts/any-chat-completions-mcp\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\n\nOr, if you clone the repo, you can build and use in your Claude Desktop configuration like this:\n\n\n```json\n\n{\n  \"mcpServers\": {\n    \"chat-openai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\nYou can add multiple providers by referencing the same MCP server multiple times, but with different env arguments:\n\n```json\n\n{\n  \"mcpServers\": {\n    \"chat-pyroprompts\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"PYROPROMPTS_KEY\",\n        \"AI_CHAT_NAME\": \"PyroPrompts\",\n        \"AI_CHAT_MODEL\": \"ash\",\n        \"AI_CHAT_BASE_URL\": \"https://api.pyroprompts.com/openaiv1\"\n      }\n    },\n    \"chat-perplexity\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"PERPLEXITY_KEY\",\n        \"AI_CHAT_NAME\": \"Perplexity\",\n        \"AI_CHAT_MODEL\": \"sonar\",\n        \"AI_CHAT_BASE_URL\": \"https://api.perplexity.ai\"\n      }\n    },\n    \"chat-openai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\nWith these three, you'll see a tool for each in the Claude Desktop Home:\n\n![Claude Desktop Home with Chat Tools](img/claude_desktop_home.png)\n\nAnd then you can chat with other LLMs and it shows in chat like this:\n\n![Claude Chat with OpenAI](img/claude_chat_openai.png)\n\nOr, configure in [LibreChat](https://www.librechat.ai/) like:\n```yaml\n  chat-perplexity:\n    type: stdio\n    command: npx\n    args:\n      - -y\n      - @pyroprompts/any-chat-completions-mcp\n    env:\n      AI_CHAT_KEY: \"pplx-012345679\"\n      AI_CHAT_NAME: Perplexity\n      AI_CHAT_MODEL: sonar\n      AI_CHAT_BASE_URL: \"https://api.perplexity.ai\"\n      PATH: '/usr/local/bin:/usr/bin:/bin'\n````\n\nAnd it shows in LibreChat:\n\n![LibreChat with Perplexity Chat](img/librechat.png)\n\n\n\n\n### Installing via Smithery\n\nTo install Any OpenAI Compatible API Integrations for Claude Desktop automatically via [Smithery](https://smithery.ai/server/any-chat-completions-mcp-server):\n\n```bash\nnpx -y @smithery/cli install any-chat-completions-mcp-server --client claude\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n### Acknowledgements\n\n- Obviously the modelcontextprotocol and Anthropic team for the MCP Specification and integration into Claude Desktop. [https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/introduction)\n- [PyroPrompts](https://pyroprompts.com?ref=github-any-chat-completions-mcp) for sponsoring this project. Use code `CLAUDEANYCHAT` for 20 free automation credits on Pyroprompts.\n"
}