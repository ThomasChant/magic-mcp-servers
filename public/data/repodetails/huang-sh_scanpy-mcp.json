{
  "mcp_name": "huang-sh/scanpy-mcp",
  "mcp_description": "Facilitates natural language-driven scRNA-Seq analysis using Scanpy, enabling seamless integration with AI clients and agent frameworks.",
  "mcp_id": "huang-sh_scanpy-mcp",
  "fetch_timestamp": "2025-06-23T04:51:13.457604Z",
  "github_url": "https://github.com/huang-sh/scanpy-mcp",
  "repository": {
    "name": "scanpy-mcp",
    "full_name": "huang-sh/scanpy-mcp",
    "description": "MCP server for Scanpy",
    "html_url": "https://github.com/huang-sh/scanpy-mcp",
    "created_at": "2025-04-09T21:10:45Z",
    "updated_at": "2025-06-15T21:56:28Z",
    "pushed_at": "2025-05-15T11:49:10Z",
    "size": 7523,
    "stargazers_count": 7,
    "watchers_count": 7,
    "forks_count": 2,
    "open_issues_count": 0,
    "language": "Python",
    "license": "BSD 3-Clause \"New\" or \"Revised\" License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "huang-sh",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/24741118?v=4",
      "html_url": "https://github.com/huang-sh"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 2,
    "subscribers_count": 2,
    "languages": {
      "Python": 155943
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 0,
    "contributors_count": 2,
    "latest_release": {
      "tag_name": "v0.1.2",
      "name": "v0.1.2",
      "published_at": "2025-04-11T14:27:51Z",
      "body": "add transport sse",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.1.2",
        "commit_sha": "87a062017e1968d4faa6e251f9c1ec5764910353"
      },
      {
        "name": "v0.1.1",
        "commit_sha": "4d9e1e4bf0506ae5ed081b54052baca45fc5c828"
      },
      {
        "name": "v0.1.0",
        "commit_sha": "d5972c38d984f7223e247eda186e2152eab80fec"
      }
    ],
    "latest_version": "v0.1.2"
  },
  "readme": "> ‚ö†Ô∏è **Important Notice**: This repository is no longer maintained. Please visit [scmcphub](https://github.com/scmcphub) for the latest version of MCP servers.\n\n\n# Scanpy MCP server\n\nAn MCP server for scRNA-Seq analysis software Scanpy with natural language!\n\n## ü™© What can it do?\n\n- IO module like read and write scRNA-Seq data with natural language\n- Preprocessing module,like filtering, quality control, normalization, scaling, highly-variable genes, PCA, Neighbors,...\n- Tool module, like clustering, differential expression etc.\n- Plotting module, like violin, heatmap, dotplot\n\n## ‚ùì Who is this for?\n\n- Anyone who wants to do scRNA-Seq analysis natural language!\n- Agent developers who want to call scanpy's functions for their applications\n\n## üåê Where to use it?\n\nYou can use scanpy-mcp in most AI clients, plugins, or agent frameworks that support the MCP:\n\n- AI clients, like Cherry Studio\n- Plugins, like Cline\n- Agent frameworks, like Agno \n\n## üé¨ Demo\n\nA demo showing scRNA-Seq cell cluster analysis in a AI client Cherry Studio using natural language based on scanpy-mcp\n\nhttps://github.com/user-attachments/assets/93a8fcd8-aa38-4875-a147-a5eeff22a559\n\n## üèéÔ∏è Quickstart\n\n### Install\n\nInstall from PyPI\n```\npip install scanpy-mcp\n```\nyou can test it by running\n```\nscmcp run\n```\n\n#### run scnapy-server locally\nRefer to the following configuration in your MCP client:\n\n```\n\"mcpServers\": {\n  \"scanpy-mcp\": {\n    \"command\": \"scanpy-mcp\",\n    \"args\": [\n      \"run\"\n    ]\n  }\n}\n```\n\n#### run scnapy-server remotely\nRefer to the following configuration in your MCP client:\n\nrun it in your server\n```\nscmcp run --transport shttp --port 8000\n```\n\nThen configure your MCP client, like this:\n```\nhttp://localhost:8000/mcp\n```\n\n## ü§ù Contributing\n\nIf you have any questions, welcome to submit an issue, or contact me(hsh-me@outlook.com). Contributions to the code are also welcome!\n"
}