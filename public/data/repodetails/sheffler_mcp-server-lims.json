{
  "mcp_name": "sheffler/mcp-server-lims",
  "mcp_description": "Facilitates AI-driven management of laboratory workflows by simulating instrument data processing and integrating with MCP tools.",
  "mcp_id": "sheffler_mcp-server-lims",
  "fetch_timestamp": "2025-06-23T08:22:01.898311Z",
  "github_url": "https://github.com/sheffler/mcp-server-lims",
  "repository": {
    "name": "mcp-server-lims",
    "full_name": "sheffler/mcp-server-lims",
    "description": "MCP Tools use for a Laboratory Information Management System ",
    "html_url": "https://github.com/sheffler/mcp-server-lims",
    "created_at": "2025-04-10T21:11:39Z",
    "updated_at": "2025-04-14T17:50:26Z",
    "pushed_at": "2025-04-14T17:50:23Z",
    "size": 469,
    "stargazers_count": 0,
    "watchers_count": 0,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": "Apache License 2.0",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "sheffler",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/93730?v=4",
      "html_url": "https://github.com/sheffler"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "Python": 4632
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 0,
    "contributors_count": 1
  },
  "readme": "# MCP SERVER LIMS\n\nThis repository hosts the MCP Server code that was presented in the video of the following LinkedIn Article.  The example illustrated Anthropic's Claude calling MCP database and simulated-instrument tools to execute the steps of a laboratory workflow.  The example is challenging in that it asks for collections of richly structured data to managed across a number of steps.\n\n[https://www.linkedin.com/pulse/ai-agent-lims-iot-mcp-tom-sheffler-ylmpc/](https://www.linkedin.com/pulse/ai-agent-lims-iot-mcp-tom-sheffler-ylmpc/)\n\n\n## Introduction\n\n\nThe goal of the LIMS (Laboratory Information Management System) example is for an AI Agent to manage the data associated with a collection of samples as they pass through a laboratory workflow.\n\nThe synthetic workflow here is a simplified version of something that you might find in a lab, but with many details omitted.  In the workflow, there is the passing of physical samples between instruments that process or analyze them.  There is also the data flow associated with the tracking of the samples as they enter an instrument and after they are processed.\n\nThe Workflow figure below presents a schematic illustrating the steps of the workflow and the data that must be managed.   Data is illustrated as a table with one entry for each sample at each step.\n\n![](./figs/Workflow01/Slide2.png)\n\n\n## The Example\n\nThe workflow begins with the arrival of samples in tubes.  There are some number of tubes.  Each has a \"sample name\" and an associated \"mass\".  The data associated with the introduction of the tubes in the lab is entered into the data tracking system.  This step is called \"accessioning.\" \n\nNow that the samples are registered in the system, they may be processed by the first instrument.  The samples are loaded into the instrument, and the data *about* the samples is also sent to that instrument.  Then the instrument can begin its processing.  This first instrument is called the \"preparation\" instrument.  Its output consists of two things.\n\n1. the prepared samples in a collection of output tubes\n2. data about each of the samples and how it was prepared\n\nIn our simulated preparation step, each sample is processed to attach a genetic tag (\"actg\", \"acac\", etc.) to the samples in the tube and the tag attached to each sample is noted in the output data.  (There is no way to know ahead of time which tag is attached to which sample.)  There is also a note about whether this step was performed successfully or not in the \"status\" field, which may be \"passed\" or \"failed\".\n\nThe prepared samples are then ready to be processed in the \"analyzer\" instrument.  The output samples from the first instrument are loaded into the second instrument and the known data about each of the samples is sent to the analyzer instrument.\n\nThe analyzer instrument consumes the phyical samples and emits data about each of the samples analyzed.  Here there is a \"filename\" and a \"metric\" measuring a quantity about the analysis step.\n\nThe final output of the execution of the workflow should be a report that summarizes information across the steps in an easy to understand format.\n\n## Simulated Instruments\n\nReal laboratory instruments do indeed process data inputs and outputs for collections of samples over protocols like HL7 or REST.  It is possible that such interfaces on real instruments could be integrated with AI Agents as \"tools\" using MCP (Model Context Protocol).\n\nIn this simuluation, rather than calling the APIs of real instruments, the tools here produce simulated results.  The \"tag\" and \"status\" values of the preparation instrument are selected randomly, as is the \"metric\" of the analyzer instrument.\n\nIn the real world, the processing of an instrument might require minutes or hours.  In our simulated instruments, we note the passing of time by processing one sample per second.\n\n\n## Challenges for the AI Agent and Tools Integration\n\nIn this example we are asking the AI agent to plan for the management of data across a sequence of steps.  An AI agent may use a database to save intermediate results, and it may find the use of a SQL database useful for preparing a final \"join\" of the data across the steps.  The Agent might also devise an alternate way of managing data or may simply include it as part of the conversation.\n\nThe workflow specification instructs that only the \"passing\" samples are processed by the analysis step.\n\nWe have also defined the tools representing the instruments with an interface with a rich type definition.  Each of the instruments accepts an array-of-structures and produces an array-of-structures.  An example of the MCP definition of \"preparation_tool\" appears below.\n\nSome notable features of the JSON Schema definition are:\n\n1. the use of named structure \"InputSample\" in the \"$defs\" stanza of the JSON\n2. the input parameter \"sample_list\" is an array\n3. the array is homogenous with all \"items\" of type \"#/$defs/InputSample\"\n\nIn our testing so far, many LLMs are able to manage data that fulfills these schema requirements.\n\n\n```\n{\n 'tools': [{'function': {'description': 'Prepare the samples for analysis.  '\n                                        \"Mark samples as 'passed' or \"\n                                        \"'failed'. \",\n                         'name': 'preparation_tool',\n                         'parameters': {\n                             '$defs': {\n                                 'InputSample': {\n                                     'properties': {\n                                         'mass': {\n                                             'description': 'sample mass in ng',\n                                             'title': 'Mass',\n                                             'type': 'integer'\n                                         },\n                                         'sample_name': {\n                                             'description': 'sample name identifier',\n                                             'title': 'Sample Name',\n                                             'type': 'string'\n                                         }\n                                     },\n                                     'required': ['sample_name', 'mass'],\n                                     'title': 'InputSample',\n                                     'type': 'object'\n                                 }\n                             },\n                             'properties': {\n                                 'sample_list': {\n                                     'items': {\n                                         '$ref': '#/$defs/InputSample'\n                                     },\n                                     'type': 'array'\n                                 }\n                             },\n                             'required': ['sample_list'],\n                             'type': 'object'\n                         }\n                     },\n            'type': 'function'\n        }]}\n```\n\n## Requirements\n\nIn addition to the LIMS Server of this repository, the Python server \"mcp-server-sqlite\" should be running as well so that the AI Agent can make use of a database.\n\nThe source code resides here.\n\n* https://github.com/modelcontextprotocol/servers/tree/main/src/sqlite\n\n\n## PROMPTS\n\nThe first prompt describes the steps of the workflow and how each step is performed by executing a tool.  Since the execution of a tool requires the availability of certain data, the Agent needs to determine how to obtain or produce that data.  The final goal given to the Agent is the production of a Workflow Report that summarizes data across all of the steps.\n\nThe beginning of this first prompt is shown below.\n\n```\nThe assistant's goal is to manage the data associated with a set of samples.  There are four steps of concern.\n\n- accessioning - entering the initial samples in the database\n- preparation - calling a tool to process the input samples to attach a tag and monitor a \"passed\" or \"failed\" status\n- analysis - calling a tool to analyze the outputs of the preparation step whose status is \"passed\"\n- report generation - displaying the sample data across the first 3 steps\n...\n```\n\n\n### A smaller tool test for smaller LLMs\n\nThe complexity of the first prompt exceeds what smaller LLMs can perform.  A second prompt aims to merely exercise the LLM's ability to format and process a tool call and transform tabular data into the array-of-structures required by the tools.\n\n(The prompt shown below has turned out to be useful for examining the correctness of tool interfaces with rich types.)\n\n```\nProcess the following table of data with the preparation_tool.\n<table>\n<tr>\n  <th>Sample Name</th> <th>Input Mass</th>\n<tr>\n<tr>\n  <td> NA12878 </td> <td> 45 </td>\n</tr\n<tr>\n  <td> NCC1701 </td> <td> 77 </td>\n</tr\n<tr>\n  <td> NACL </td> <td> 12 </td>\n</tr\n<tr>\n  <td> NA12879 </td> <td> 32 </td>\n</tr\n</table>\n```\n\n## How to Build and Run\n\nMake sure you have `uv` installed.\n\n    $ git clone https://github.com/sheffler/mcp-server-lims\n    $ cd mcp-server-lims\n    $ uv init\n    $ uv venv\n    $ . .venv/bin/activate\n    $ uv sync\n\n\nAt this point the dependencies for the MCP server SDK should be installed in the venv.\n\n### Configuration for Claude Desktop\n\nConfigure Claude Desktop by editing\n\n* ~/Library/Application Support/Claude/claude_desktop_config.json\n\n\n```\n{\n  \"mcpServers\": {\n    \"mcp-lims-server\" : {\n      \"command\": \"/Users/sheffler/git/mcp-server-lims/.venv/bin/python\",\n      \"args\": [\n        \"/Users/sheffler/git/mcp-server-lims/lims_server.py\"\n      ]\n    },\n    \"sqlite\": {\n      \"command\": \"/Users/sheffler/.local/bin/uvx\",\n      \"args\": [\n        \"mcp-server-sqlite\",\n        \"--db-path\",\n        \"/Users/sheffler/test.db\"\n      ]\n    },\n  }\n}\n```\n\n\n## Configuration for Oterm\n\n~/Library/Application Support/oterm/config.json\n\n```\n{\"theme\": \"textual-dark\",\n \"splash-screen\": false,\n \"mcpServers\": {\n\n    \"mcp-lims-server\" : {\n      \"command\": \"/Users/sheffler/git/mcp-server-lims/.venv/bin/python\",\n      \"args\": [\n        \"/Users/sheffler/git/mcp-server-lims/lims_server.py\"\n      ]\n    },\n\n    \"sqlite\": {\n      \"command\": \"/Users/sheffler/.local/bin/uvx\",\n      \"args\": [\n        \"mcp-server-sqlite\",\n        \"--db-path\",\n        \"/Users/sheffler/test.db\"\n      ]\n    },\n\n }\n}\n```\n\n\n## Workflow Report generated by Claude\n\n\nAn example output report generated by Claude (with Claude Desktop) is shown below.\n\n![](./figs/claude-report.png)\n\n\n## Transcript\n\nA transcript of the conversation with Claude is included for reference.\n\n* [./lims-claude-transcript.docx](./lims-claude-transcript.docx)\n* [./lims-claude-transcript.pdf](./lims-claude-transcript.pdf)\n\n"
}