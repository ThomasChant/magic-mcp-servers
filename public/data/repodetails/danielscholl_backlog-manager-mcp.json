{
  "mcp_name": "danielscholl/backlog-manager-mcp",
  "mcp_description": "A task tracking and backlog management server for AI assistants, utilizing Anthropic's MCP protocol for seamless integration with AI clients.",
  "mcp_id": "danielscholl_backlog-manager-mcp",
  "fetch_timestamp": "2025-06-23T02:26:39.354384Z",
  "github_url": "https://github.com/danielscholl/backlog-manager-mcp",
  "repository": {
    "name": "backlog-manager-mcp",
    "full_name": "danielscholl/backlog-manager-mcp",
    "description": "Play project for MCP Server Learning",
    "html_url": "https://github.com/danielscholl/backlog-manager-mcp",
    "created_at": "2025-04-17T00:36:46Z",
    "updated_at": "2025-04-17T00:37:22Z",
    "pushed_at": "2025-04-17T00:37:18Z",
    "size": 62,
    "stargazers_count": 0,
    "watchers_count": 0,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": null,
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "danielscholl",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/26447046?v=4",
      "html_url": "https://github.com/danielscholl"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "Python": 21531,
      "Dockerfile": 288
    },
    "language_percentages": {
      "Python": 98.68,
      "Dockerfile": 1.32
    },
    "pull_requests_count": 0,
    "contributors_count": 1
  },
  "readme": "# Backlog Manager MCP Server\n\n> A simple task tracking and backlog management MCP server for AI assistants (hack project)\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/Status-Beta-yellow\" alt=\"Status: Beta\">\n  <img src=\"https://img.shields.io/badge/Python-3.12%2B-green\" alt=\"Python: 3.12+\">\n</p>\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Features](#features)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Running the Server](#running-the-server)\n- [MCP Tools](#mcp-tools)\n- [Integration with MCP Clients](#integration-with-mcp-clients)\n- [Usage Examples](#usage-examples)\n- [Troubleshooting](#troubleshooting)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Overview\n\nBacklog Manager is an MCP (Machine-Consumable Programming) server for issue and task management with a file-based approach. It provides tools for AI agents and other clients to create issues, add tasks to them, and track task status. Issues represent high-level feature requests or bugs, while tasks represent specific work items needed to resolve the issue.\n\nBuilt using Anthropic's MCP protocol, it supports both SSE and stdio transports for flexible integration with AI assistants like Claude, or other MCP-compatible clients.\n\n## Features\n\n- **Issue Management**: Create, list, select, and track issues with descriptions\n- **Task Tracking**: Add tasks to issues with titles, descriptions, and status tracking\n- **Status Workflow**: Track task progress through New, InWork, and Done states\n- **File-Based Storage**: Portable JSON storage format for easy backup and version control\n- **Flexible Transport**: Support for both SSE (HTTP) and stdio communication\n- **Docker Support**: Run in containers for easy deployment and isolation\n\n## Prerequisites\n\n- **Python**: 3.12 or higher\n- **Package Manager**: uv (recommended) or pip\n- **Docker**: (Optional) For containerized deployment\n- **MCP Client**: Claude Code, Windsurf, or any other MCP-compatible client\n\n## Installation\n\n### Using uv (Recommended)\n\n```bash\n# Clone the repository\ngit clone https://github.com/username/backlog-manager-mcp.git\ncd backlog-manager-mcp\n\n# Install dependencies\nuv pip install -e .\n\n# Verify installation\nuv run backlog-manager  # This should start the server\n```\n\n### Using Docker\n\n```bash\n# Build the Docker image\ndocker build -t backlog/manager --build-arg PORT=8050 .\n\n# Run the container\ndocker run -p 8050:8050 backlog/manager\n\n# Verify container is running\ndocker ps | grep backlog/manager\n```\n\n## Configuration\n\nConfigure the server behavior using environment variables in a `.env` file:\n\n```bash\n# Create environment file from example\ncp .env.example .env\n```\n\nExample `.env` file content:\n\n```\n# Transport mode: 'sse' or 'stdio'\nTRANSPORT=sse\n\n# Server configuration (for SSE transport)\nHOST=0.0.0.0\nPORT=8050\n\n# Data storage\nTASKS_FILE=tasks.json\n```\n\n| Variable     | Description                                | Default      | Required |\n| ------------ | ------------------------------------------ | ------------ | -------- |\n| `TRANSPORT`  | Transport protocol (sse or stdio)          | `sse`        | No       |\n| `HOST`       | Host to bind to when using SSE transport   | `0.0.0.0`    | No       |\n| `PORT`       | Port to listen on when using SSE transport | `8050`       | No       |\n| `TASKS_FILE` | Path to the tasks storage file             | `tasks.json` | No       |\n\n## Running the Server\n\n### Start the Server (SSE Mode)\n\n```bash\n# Using the CLI command\nuv run backlog-manager\n\n# Or directly with Python\nuv run src/backlog_manager/main.py\n```\n\nYou should see output similar to:\n\n```\nINFO:     Started server process [12345]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8050 (Press CTRL+C to quit)\n```\n\n> **Note**: The server does not support the `--help` flag since it's designed as an MCP server, not a traditional CLI application.\n\n### Using stdio Mode\n\nWhen using stdio mode, you don't need to start the server separately - the MCP client will start it automatically when configured properly (see [Integration with MCP Clients](#integration-with-mcp-clients)).\n\n## MCP Tools\n\nThe Backlog Manager exposes the following tools via MCP:\n\n### Issue Management\n\n| Tool                  | Description               | Parameters                                                                     |\n| --------------------- | ------------------------- | ------------------------------------------------------------------------------ |\n| `create_issue`        | Create a new issue        | `name` (string), `description` (string, optional), `status` (string, optional) |\n| `list_issues`         | Show all available issues | None                                                                           |\n| `select_issue`        | Set the active issue      | `name` (string)                                                                |\n| `initialize_issue`    | Create or reset an issue  | `name` (string), `description` (string, optional), `status` (string, optional) |\n| `update_issue_status` | Update issue status       | `name` (string), `status` (string)                                             |\n\n### Task Management\n\n| Tool                 | Description                | Parameters                                         |\n| -------------------- | -------------------------- | -------------------------------------------------- |\n| `add_task`           | Add task to active issue   | `title` (string), `description` (string, optional) |\n| `list_tasks`         | List tasks in active issue | `status` (string, optional)                        |\n| `update_task_status` | Update task status         | `task_id` (string), `status` (string)              |\n\n### Status Values\n\nTasks and issues can have one of the following statuses:\n\n- `New` (default for new tasks/issues)\n- `InWork` (in progress)\n- `Done` (completed)\n\n## Integration with MCP Clients\n\n### SSE Configuration\n\nOnce you have the server running with SSE transport, connect to it using this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"backlog-manager\": {\n      \"transport\": \"sse\",\n      \"url\": \"http://localhost:8050/sse\"\n    }\n  }\n}\n```\n\n**Windsurf Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"backlog-manager\": {\n      \"transport\": \"sse\",\n      \"serverUrl\": \"http://localhost:8050/sse\"\n    }\n  }\n}\n```\n\n**n8n Configuration:**\n\nUse `host.docker.internal` instead of `localhost` to access the host machine from n8n container:\n\n```\nhttp://host.docker.internal:8050/sse\n```\n\n### Python with Stdio Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"backlog-manager\": {\n      \"command\": \"python\",\n      \"args\": [\"path/to/backlog-manager/src/backlog_manager/main.py\"],\n      \"env\": {\n        \"TRANSPORT\": \"stdio\",\n        \"TASKS_FILE\": \"tasks.json\"\n      }\n    }\n  }\n}\n```\n\n### Docker with Stdio Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"backlog-manager\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"--rm\", \"-i\", \"-e\", \"TRANSPORT=stdio\", \"backlog/manager\"],\n      \"env\": {\n        \"TRANSPORT\": \"stdio\"\n      }\n    }\n  }\n}\n```\n\n## Example\n\nBacklog Manager is designed to work seamlessly with AI assistants to help you organize your project work. The most powerful use case is having the AI read specifications and automatically create a structured backlog.\n\nSimply ask your AI assistant:\n\n```\nRead the spec and create a backlog for features not completed.\n```\n\nThe AI assistant will:\n\n1. Read and analyze the specification document\n2. Identify key features and components\n3. Create issues for main functional areas\n4. Break down each issue into specific tasks\n5. Organize everything in a structured backlog\n"
}