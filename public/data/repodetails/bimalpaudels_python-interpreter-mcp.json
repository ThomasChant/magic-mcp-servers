{
  "mcp_name": "bimalpaudels/python-interpreter-mcp",
  "mcp_description": "Facilitates the execution of Python scripts in a controlled environment using LLMs.",
  "mcp_id": "bimalpaudels_python-interpreter-mcp",
  "fetch_timestamp": "2025-06-23T01:38:53.337691Z",
  "github_url": "https://github.com/bimalpaudels/python-interpreter-mcp",
  "repository": {
    "name": "python-interpreter-mcp",
    "full_name": "bimalpaudels/python-interpreter-mcp",
    "description": "A Model Context Server providing simple features to automate python script execution via LLMs.",
    "html_url": "https://github.com/bimalpaudels/python-interpreter-mcp",
    "created_at": "2025-04-17T20:18:08Z",
    "updated_at": "2025-04-23T08:06:28Z",
    "pushed_at": "2025-04-23T08:06:24Z",
    "size": 24,
    "stargazers_count": 1,
    "watchers_count": 1,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": "MIT License",
    "topics": [
      "automation",
      "llm",
      "mcp-server",
      "python"
    ],
    "default_branch": "main",
    "owner": {
      "login": "bimalpaudels",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/38532664?v=4",
      "html_url": "https://github.com/bimalpaudels"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": false,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "Python": 3610
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 6,
    "contributors_count": 1
  },
  "readme": "## python-interpreter-mcp: A MCP server to run scripts\n\n## Overview\nA lightweight, experimental MCP server designed to execute arbitrary Python scripts in a structured and reproducible environment. It leverages **[uv](https://github.com/astral-sh/uv)** to run isolated code snippets through subprocesses.\n\n\n### Tools\n- `run_script`\n   - Runs the given script with `uv run script.py`.\n   - Input: \n     - `code`(str): Script to be run\n   - Return: The stdout of the given script.\n\n## Configuration\n### Usage with OpenAI Agents SDK\n\n```python\nasync with MCPServerStdio(\n            params={\n                \"command\": \"uvx\",\n                \"args\": [\"python-interpreter-mcp\"],\n            }\n    ) as server\n...\n```\n\n### Usage with Claude Desktop\nAdd this to your `claude_desktop_config.json`:\n```json\n\"mcpServers\": {\n  \"interpreter\": {\n    \"command\": \"uvx\",\n    \"args\": [\"python-interpreter-mcp\"]\n  }\n}\n```\n\n## How it works\n\n- A script string is received by the MCP tool `run_script`.\n- A hidden folder is created in cwd, and the script is saved as a `.py` file inside it.\n- The script is then executed using `uv run`, which ensures dependency isolation.\n- The stdout of the script is captured and returned as the response.\n\n## Usage Warnings\n**This project is in a very early stage of development.**\n\n### ⚠️ Important notes\n- It executes arbitrary Python code, which means it can run anything — including malicious or destructive commands.\n- Use only in trusted, sandboxed environments.\n- You should always validate, guardrail, or restrict inputs when wiring this into an LLM."
}