{
  "mcp_name": "XGenerationLab/xiyan_mcp_server",
  "mcp_description": "üìá ‚òÅÔ∏è ‚Äî An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.",
  "mcp_id": "XGenerationLab_xiyan_mcp_server",
  "fetch_timestamp": "2025-06-23T09:31:13.388242Z",
  "github_url": "https://github.com/XGenerationLab/xiyan_mcp_server",
  "repository": {
    "name": "xiyan_mcp_server",
    "full_name": "XGenerationLab/xiyan_mcp_server",
    "description": "A Model Context Protocol (MCP) server that enables natural language queries to databases",
    "html_url": "https://github.com/XGenerationLab/xiyan_mcp_server",
    "created_at": "2025-03-13T07:39:00Z",
    "updated_at": "2025-06-23T07:30:23Z",
    "pushed_at": "2025-05-07T11:06:19Z",
    "size": 2267,
    "stargazers_count": 163,
    "watchers_count": 163,
    "forks_count": 28,
    "open_issues_count": 9,
    "language": "Python",
    "license": "Apache License 2.0",
    "topics": [
      "database",
      "mcp",
      "text-to-sql"
    ],
    "default_branch": "main",
    "owner": {
      "login": "XGenerationLab",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/188174443?v=4",
      "html_url": "https://github.com/XGenerationLab"
    },
    "has_issues": true,
    "has_projects": false,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 28,
    "subscribers_count": 8,
    "languages": {
      "Python": 35910,
      "Dockerfile": 211
    },
    "language_percentages": {
      "Python": 99.42,
      "Dockerfile": 0.58
    },
    "pull_requests_count": 3,
    "contributors_count": 5,
    "latest_release": {
      "tag_name": "v0.1.4",
      "name": "v0.1.4",
      "published_at": "2025-03-24T03:00:03Z",
      "body": "- Support PostgreSQL",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.1.5",
        "commit_sha": "d153a94e7fcc508202427f733d5c8589fa80072a"
      },
      {
        "name": "v0.1.4",
        "commit_sha": "714223870550165f532f1a9a4cefdcfdae326b45"
      },
      {
        "name": "v0.1.3",
        "commit_sha": "523de16d15d45fd92c0e22bf94a3847b7e530199"
      },
      {
        "name": "v0.1.2",
        "commit_sha": "257098b90f12ef31ef5ffdbc7d10fef5d884d9b7"
      },
      {
        "name": "v0.1.1",
        "commit_sha": "c7f7d772a7b955d7a52137b869c4e1a86b83abc7"
      },
      {
        "name": "v0.1.0",
        "commit_sha": "b5240409bfa67e2abbd87a8ee58180561b1d65a2"
      }
    ],
    "latest_version": "v0.1.5"
  },
  "readme": "\n<h1 align=\"center\">XiYan MCP Server</h1>\n<p align=\"center\">\n  <a href=\"https://github.com/XGenerationLab/XiYan-SQL\"><img alt=\"MCP Playwright\" src=\"https://raw.githubusercontent.com/XGenerationLab/XiYan-SQL/main/xiyanGBI.png\" height=\"60\"/></a>\n</p>\n<p align=\"center\">\n  <b>A Model Context Protocol (MCP) server that enables natural language queries to databases</b><br/>\n  <sub>powered by <a href=\"https://github.com/XGenerationLab/XiYan-SQL\" >XiYan-SQL</a>, SOTA of text-to-sql on open benchmarks</sub>\n</p>\n<p align=\"center\">\nüíª <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server\" >XiYan-mcp-server</a> | \nüåê <a href=\"https://github.com/XGenerationLab/XiYan-SQL\" >XiYan-SQL</a> |\nüìñ <a href=\"https://arxiv.org/abs/2411.08599\"> Arxiv</a> | \nüìÑ <a href=\"https://paperswithcode.com/paper/xiyan-sql-a-multi-generator-ensemble\" >PapersWithCode</a>\nü§ó <a href=\"https://huggingface.co/collections/XGenerationLab/xiyansql-models-67c9844307b49f87436808fc\">HuggingFace</a> |\nü§ñ <a href=\"https://modelscope.cn/collections/XiYanSQL-Models-4483337b614241\" >ModelScope</a> |\nüåï <a href=\"https://bailian.console.aliyun.com/xiyan\">ÊûêË®ÄGBI</a> \n<br />\n<img src=\"https://badge.mcpx.dev/?type=server%20%27MCP%20Server%27\" alt=\"MCP Server\" />\n<a href=\"https://arxiv.org/abs/2411.08599\"><img src=\"imgs/Paper-Arxiv-orange.svg\" ></a>\n<a href=\"https://opensource.org/licenses/Apache-2.0\">\n  <img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License: Apache 2.0\" />\n</a>\n<a href=\"https://pepy.tech/projects/xiyan-mcp-server\"><img src=\"https://static.pepy.tech/badge/xiyan-mcp-server\" alt=\"PyPI Downloads\"></a>\n  <a href=\"https://smithery.ai/server/@XGenerationLab/xiyan_mcp_server\"><img alt=\"Smithery Installs\" src=\"https://smithery.ai/badge/@XGenerationLab/xiyan_mcp_server\" height=\"20\"/></a>\n<a href=\"https://github.com/XGenerationLab/xiyan_mcp_server\" target=\"_blank\">\n    <img src=\"https://img.shields.io/github/stars/XGenerationLab/xiyan_mcp_server?style=social\" alt=\"GitHub stars\" />\n</a>\n<br />\n<a href=\"https://github.com/XGenerationLab/xiyan_mcp_server\" >English</a> | <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/README_zh.md\"> ‰∏≠Êñá </a> | <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/README_ja.md\"> Êó•Êú¨Ë™û </a><br />\n<a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/imgs/dinggroup_out.png\">Ding GroupÈíâÈíâÁæ§</a>ÔΩú \n<a href=\"https://weibo.com/u/2540915670\" target=\"_blank\">Follow me on Weibo</a>\n</p>\n\n\n## Table of Contents\n\n- [Features](#features)\n- [Preview](#preview)\n  - [Architecture](#architecture)\n  - [Best Practice](#best-practice)\n  - [Tools Preview](#tools-preview)\n- [Installation](#installation)\n  - [Installing from pip](#installing-from-pip)\n  - [Installing from Smithery.ai](#installing-from-smitheryai)\n- [Configuration](#configuration)\n  - [LLM Configuration](#llm-configuration)\n    - [General LLMs](#general-llms)\n    - [Text-to-SQL SOTA model](#text-to-sql-sota-model)\n    - [Local Model](#local-model)\n  - [Database Configuration](#database-configuration)\n    - [MySQL](#mysql)\n    - [PostgreSQL](#postgresql)\n- [Launch](#launch)\n  - [Claude Desktop](#claude-desktop)\n  - [Cline](#cline)\n  - [Goose](#goose)\n  - [Cursor](#cursor)\n- [It Does Not Work](#it-does-not-work)\n- [Citation](#citation)\n\n\n## Features\n- üåê Fetch data by natural language through [XiYanSQL](https://github.com/XGenerationLab/XiYan-SQL)\n- ü§ñ Support general LLMs (GPT,qwenmax), Text-to-SQL SOTA model\n- üíª Support pure local mode (high security!)\n- üìù Support MySQL and PostgreSQL. \n- üñ±Ô∏è List available tables as resources\n- üîß Read table contents\n\n## Preview\n### Architecture\nThere are two ways to integrate this server in your project, as shown below:\nThe left is remote mode, which is the default mode. It requires an API key to access the xiyanSQL-qwencoder-32B model from service provider (see [Configuration](#Configuration)).\nAnother mode is local mode, which is more secure. It does not require the API key.\n\n![architecture.png](imgs/architecture.png)\n### Best practice and reports\n\n[\"Build a local data assistant using MCP + Modelscope API-Inference without writing a single line of code\"](https://mp.weixin.qq.com/s/tzDelu0W4w6t9C0_yYRbHA)\n\n[\"Xiyan MCP on Modelscope\"](https://modelscope.cn/headlines/article/1142)\n\n### Evaluation on MCPBench\nThe following figure illustrates the performance of the XiYan MCP server as measured by the MCPBench benchmark. The XiYan MCP server demonstrates superior performance compared to both the MySQL MCP server and the PostgreSQL MCP server, achieving a lead of 2-22 percentage points. The detailed experiment results can be found at [MCPBench](https://github.com/modelscope/MCPBench) and the report [\"Evaluation Report on MCP Servers\"](https://arxiv.org/abs/2504.11094).\n\n![exp_mcpbench.png](imgs/exp_mcpbench.png)\n\n### Tools Preview\n - The tool ``get_data`` provides a natural language interface for retrieving data from a database. This server will convert the input natural language into SQL using a built-in model and call the database to return the query results.\n\n - The ``{dialect}://{table_name}`` resource allows obtaining a portion of sample data from the database for model reference when a specific table_name is specified. \n- The ``{dialect}://`` resource will list the names of the current databases\n\n## Installation\n### Installing from pip\n\nPython 3.11+ is required. \nYou can install the server through pip, and it will install the latest version:\n\n```shell\npip install xiyan-mcp-server\n```\n\nIf you want to install the development version from source, you can install from source code on github:\n```shell\npip install git+https://github.com/XGenerationLab/xiyan_mcp_server.git\n```\n\n### Installing from Smithery.ai\nSee [@XGenerationLab/xiyan_mcp_server](https://smithery.ai/server/@XGenerationLab/xiyan_mcp_server)\n\nNot fully tested.\n\n## Configuration\n\nYou need a YAML config file to configure the server.\nA default config file is provided in config_demo.yml which looks like this:\n\n```yaml\nmcp:\n  transport: \"stdio\"\nmodel:\n  name: \"XGenerationLab/XiYanSQL-QwenCoder-32B-2412\"\n  key: \"\"\n  url: \"https://api-inference.modelscope.cn/v1/\"\ndatabase:\n  host: \"localhost\"\n  port: 3306\n  user: \"root\"\n  password: \"\"\n  database: \"\"\n```\n\n### MCP Configuration\nYou can set the transport protocol to ``stdio`` or ``sse``.\n#### STDIO\nFor stdio protocol, you can set just like this:\n```yaml\nmcp:\n  transport: \"stdio\"\n```\n#### SSE\nFor sse protocol, you can set mcp config as below:\n```yaml\nmcp:\n  transport: \"sse\"\n  port: 8000\n  log_level: \"INFO\"\n```\nThe default port is `8000`. You can change the port if needed. \nThe default log level is `ERROR`. We recommend to set log level to `INFO` for more detailed information.\n\nOther configurations like `debug`, `host`, `sse_path`, `message_path` can be customized as well, but normally you don't need to modify them.\n\n### LLM Configuration\n``Name`` is the name of the model to use, ``key`` is the API key of the model, ``url`` is the API url of the model. We support following models.\n\n| versions | general LLMs(GPT,qwenmax)                                             | SOTA model by Modelscope                   | SOTA model by Dashscope                                   | Local LLMs            |\n|----------|-------------------------------|--------------------------------------------|-----------------------------------------------------------|-----------------------|\n| description| basic, easy to use | best performance, stable, recommand        | best performance, for trial                               | slow, high-security   |\n| name     | the official model name (e.g. gpt-3.5-turbo,qwen-max)                 | XGenerationLab/XiYanSQL-QwenCoder-32B-2412 | xiyansql-qwencoder-32b                                    | xiyansql-qwencoder-3b |\n| key      | the API key of the service provider (e.g. OpenAI, Alibaba Cloud)      | the API key of modelscope                  | the API key via email                                     | \"\"                    |\n| url      | the endpoint of the service provider (e.g.\"https://api.openai.com/v1\") | https://api-inference.modelscope.cn/v1/    | https://xiyan-stream.biz.aliyun.com/service/api/xiyan-sql | http://localhost:5090 |\n\n#### General LLMs\nIf you want to use the general LLMs, e.g. gpt3.5, you can directly config like this:\n```yaml\nmodel:\n  name: \"gpt-3.5-turbo\"\n  key: \"YOUR KEY \"\n  url: \"https://api.openai.com/v1\"\ndatabase:\n```\n\nIf you want to use Qwen from Alibaba, e.g. Qwen-max, you can use following config:\n```yaml\nmodel:\n  name: \"qwen-max\"\n  key: \"YOUR KEY \"\n  url: \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\ndatabase:\n```\n#### Text-to-SQL SOTA model\nWe recommend the XiYanSQL-qwencoder-32B (https://github.com/XGenerationLab/XiYanSQL-QwenCoder), which is the SOTA model in text-to-sql, see [Bird benchmark](https://bird-bench.github.io/).\nThere are two ways to use the model. You can use either of them.\n(1) [Modelscope](https://www.modelscope.cn/models/XGenerationLab/XiYanSQL-QwenCoder-32B-2412),  (2) Alibaba Cloud DashScope.\n\n\n##### (1) Modelscope version\nYou need to apply a ``key`` of API-inference from Modelscope, https://www.modelscope.cn/docs/model-service/API-Inference/intro\nThen you can use the following config:\n```yaml\nmodel:\n  name: \"XGenerationLab/XiYanSQL-QwenCoder-32B-2412\"\n  key: \"\"\n  url: \"https://api-inference.modelscope.cn/v1/\"\n```\n\nRead our [model description](https://www.modelscope.cn/models/XGenerationLab/XiYanSQL-QwenCoder-32B-2412) for more details. \n\n##### (2) Dashscope version\n\nWe deployed the model on Alibaba Cloud DashScope, so you need to set the following environment variables:\nSend me your email to get the ``key``. ( godot.lzl@alibaba-inc.com )\nIn the email, please attach the following information:\n```yaml\nname: \"YOUR NAME\",\nemail: \"YOUR EMAIL\",\norganization: \"your college or Company or Organization\"\n```\nWe will send you a ``key`` according to your email. And you can fill the ``key`` in the yml file.\nThe ``key`` will be expired by  1 month or 200 queries or other legal restrictions.\n\n\n```yaml\nmodel:\n  name: \"xiyansql-qwencoder-32b\"\n  key: \"KEY\"\n  url: \"https://xiyan-stream.biz.aliyun.com/service/api/xiyan-sql\"\n```\n\nNote: this model service is just for trial, if you need to use it in production, please contact us.\n\n##### (3) Local version\nAlternatively, you can also deploy the model [XiYanSQL-qwencoder-32B](https://github.com/XGenerationLab/XiYanSQL-QwenCoder) on your own server.\nSee [Local Model](src/xiyan_mcp_server/local_model/README.md) for more details.\n\n\n### Database Configuration\n``host``, ``port``, ``user``, ``password``, ``database`` are the connection information of the database.\n\nYou can use local or any remote databases. Now we support MySQL and PostgreSQL(more dialects soon).\n\n#### MySQL\n\n```yaml\ndatabase:\n  host: \"localhost\"\n  port: 3306\n  user: \"root\"\n  password: \"\"\n  database: \"\"\n```\n#### PostgreSQL\nStep 1: Install Python packages\n```bash\npip install psycopg2\n```\nStep 2: prepare the config.yml like this:\n```yaml\ndatabase:\n  dialect: \"postgresql\"\n  host: \"localhost\"\n  port: 5432\n  user: \"\"\n  password: \"\"\n  database: \"\"\n```\n\nNote that ``dialect`` should be ``postgresql`` for postgresql.\n## Launch\n\n### Server Launch\n\nIf you want to launch server with `sse`, you have to run the following command in a terminal:\n```shell\nYML=path/to/yml python -m xiyan_mcp_server\n```\nThen you should see the information on http://localhost:8000/sse in your browser. (Defaultly, change if your mcp server runs on other host/port)\n\nOtherwise, if you use `stdio` transport protocol, you usually declare the mcp server command in specific mcp application instead of launching it in a terminal.\nHowever, you can still debug with this command if needed.\n\n### Client Setting\n\n#### Claude Desktop\nAdd this in your Claude Desktop config file, ref <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/imgs/claude_desktop.jpg\">Claude Desktop config example</a>\n```json\n{\n    \"mcpServers\": {\n        \"xiyan-mcp-server\": {\n            \"command\": \"/xxx/python\",\n            \"args\": [\n                \"-m\",\n                \"xiyan_mcp_server\"\n            ],\n            \"env\": {\n                \"YML\": \"PATH/TO/YML\"\n            }\n        }\n    }\n}\n```\n**Please note that the Python command here requires the complete path to the Python executable (`/xxx/python`); otherwise, the Python interpreter cannot be found. You can determine this path by using the command `which python`. The same applies to other applications as well.**\n\nClaude Desktop currently does not support the SSE transport protocol.\n\n#### Cline\nPrepare the config like [Claude Desktop](#claude-desktop)\n\n#### Goose\nIf you use `stdio`, add following command in the config, ref <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/imgs/goose.jpg\">Goose config example</a>\n```shell\nenv YML=path/to/yml /xxx/python -m xiyan_mcp_server\n```\nOtherwise, if you use `sse`, change Type to `SSE` and set the endpoint to `http://127.0.0.1:8000/sse`\n#### Cursor\nUse the similar command as follows.\n\nFor `stdio`:\n```json\n{\n  \"mcpServers\": {\n    \"xiyan-mcp-server\": {\n      \"command\": \"/xxx/python\",\n      \"args\": [\n        \"-m\",\n        \"xiyan_mcp_server\"\n      ],\n      \"env\": {\n        \"YML\": \"path/to/yml\"\n      }\n    }\n  }\n}\n```\nFor `sse`:\n```json\n{\n  \"mcpServers\": {\n    \"xiyan_mcp_server_1\": {\n      \"url\": \"http://localhost:8000/sse\"\n    }\n  }\n}\n```\n\n\n#### Witsy\nAdd following in command:\n```shell\n/xxx/python -m xiyan_mcp_server\n```\nAdd an env: key is YML and value is the path to your yml file.\nRef <a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/imgs/witsy.jpg\">Witsy config example</a>\n\n\n## It Does Not Work!\nContact us:\n<a href=\"https://github.com/XGenerationLab/xiyan_mcp_server/blob/main/imgs/dinggroup_out.png\">Ding GroupÈíâÈíâÁæ§</a>ÔΩú \n<a href=\"https://weibo.com/u/2540915670\" target=\"_blank\">Follow me on Weibo</a>\n\n\n## Other Related Links\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/xgenerationlab-xiyan-mcp-server-badge.png)](https://mseep.ai/app/xgenerationlab-xiyan-mcp-server)\n\n\n\n\n## Citation\nIf you find our work helpful, feel free to give us a cite.\n```bib\n@article{xiyansql,\n      title={A Preview of XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL}, \n      author={Yingqi Gao and Yifu Liu and Xiaoxia Li and Xiaorong Shi and Yin Zhu and Yiming Wang and Shiqi Li and Wei Li and Yuntao Hong and Zhiling Luo and Jinyang Gao and Liyu Mou and Yu Li},\n      year={2024},\n      journal={arXiv preprint arXiv:2411.08599},\n      url={https://arxiv.org/abs/2411.08599},\n      primaryClass={cs.AI}\n}\n```\n"
}