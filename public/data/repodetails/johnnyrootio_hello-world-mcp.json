{
  "mcp_name": "johnnyrootio/hello-world-mcp",
  "mcp_description": "A minimal FastMCP-based server demonstrating core MCP concepts with tools, resources, and prompts, integrated with Uvicorn for production readiness.",
  "mcp_id": "johnnyrootio_hello-world-mcp",
  "fetch_timestamp": "2025-06-23T05:31:53.120783Z",
  "github_url": "https://github.com/johnnyrootio/hello-world-mcp",
  "repository": {
    "name": "hello-world-mcp",
    "full_name": "johnnyrootio/hello-world-mcp",
    "description": null,
    "html_url": "https://github.com/johnnyrootio/hello-world-mcp",
    "created_at": "2025-04-24T08:43:08Z",
    "updated_at": "2025-04-24T08:45:52Z",
    "pushed_at": "2025-04-24T08:45:48Z",
    "size": 11,
    "stargazers_count": 0,
    "watchers_count": 0,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": null,
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "johnnyrootio",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/168106723?v=4",
      "html_url": "https://github.com/johnnyrootio"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "Python": 10788,
      "Shell": 5515
    },
    "language_percentages": {
      "Python": 66.17,
      "Shell": 33.83
    },
    "pull_requests_count": 0,
    "contributors_count": 1
  },
  "readme": "# Hello World MCP Server\n\nA simple FastMCP-based server implementing a Hello World example with tools, resources, and prompts.\n\n## Overview\n\nThis is a minimal but fully representative MCP (Machine Conversation Protocol) server built using the `fastmcp` framework in Python. It serves as a demonstration of core MCP concepts and functionality.\n\nThe server includes:\n\n- **Tools**: Functions that can be called by agents\n  - `say_hello`: Greets a user by name and logs the interaction\n  - `get_greeting_log`: Returns a list of previously greeted names\n  - `clear_log`: Clears the greeting history\n  \n- **Resources**: Shared state components\n  - `greetings://log`: Resource URI that provides access to the greeting log\n\n- **Prompts**: Natural language instructions for agents\n  - `greet_user`: Template for creating a prompt to greet someone\n\n## Uvicorn Integration\n\nThis project showcases a production-ready setup using Uvicorn as the ASGI server. Uvicorn offers several advantages:\n\n- **Performance**: Uvicorn is built on uvloop (an asyncio event loop) and httptools for high performance\n- **Concurrency**: Better handling of concurrent requests\n- **Production-ready**: Suitable for production deployments with features like TLS support and process management\n- **Scaling**: Can be placed behind a reverse proxy like Nginx for horizontal scaling\n\nThe integration works by:\n1. Creating an ASGI application from FastMCP using `mcp.sse_app()` \n2. Exposing this application to Uvicorn at `main:app`\n3. Running Uvicorn programmatically with appropriate settings\n\n## Setup\n\n1. **Create and activate a virtual environment**\n   ```bash\n   python -m venv .venv\n   source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n   ```\n\n2. **Install dependencies**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Run the server**\n   ```bash\n   ./setup_and_run.sh\n   ```\n\n   The server will start on port 4242 with the MCP endpoint available at `/sse`.\n\n### Running Options\n\nThe setup script supports several options:\n\n```bash\n./setup_and_run.sh [options]\n```\n\nAvailable options:\n- `--no-uvicorn`: Use the built-in FastMCP transport instead of Uvicorn\n- `--foreground`: Run the server in the foreground (useful for debugging)\n- `--port=PORT`: Specify a custom port (default: 4242)\n- `--host=HOST`: Specify a custom host (default: 0.0.0.0)\n- `--help`: Show all available options\n\nExamples:\n```bash\n# Run in foreground mode for debugging\n./setup_and_run.sh --foreground\n\n# Run on a different port\n./setup_and_run.sh --port=8000\n\n# Run without Uvicorn (using built-in transport)\n./setup_and_run.sh --no-uvicorn\n```\n\n### Server Modes\n\nThe server can run in two distinct modes:\n\n1. **Uvicorn Mode (Default)**\n   ```bash\n   ./setup_and_run.sh\n   ```\n   This mode uses Uvicorn as the ASGI server. You'll see log messages like:\n   ```\n   INFO:     Started server process [1234]\n   INFO:     Uvicorn running on http://0.0.0.0:4242\n   ```\n\n2. **Built-in Transport Mode**\n   ```bash\n   ./setup_and_run.sh --no-uvicorn\n   ```\n   This mode uses FastMCP's built-in transport. You'll see log messages like:\n   ```\n   [04/23/25 hh:mm:ss] INFO     Starting server \"Hello World MCP Server\"...\n   ```\n\n## Testing\n\nYou can quickly test the server with:\n\n```bash\n./test_server.sh\n```\n\nThis will start the server, run the test client, and then (optionally) shut down the server when testing is complete.\n\n### Using the Test Client\n\nWe provide a test client that demonstrates how to interact with the MCP server:\n\n```bash\npython test_client.py\n```\n\nThis will:\n1. Test available endpoints\n2. Connect to the SSE endpoint\n3. List available tools, resources, and prompts\n4. Execute each tool to demonstrate functionality\n\n#### Expected Output\n\nWhen you run the test client, you'll see output similar to this:\n\n```\nTesting raw endpoints:\n  /: 404\n  /tools: 404\n  /mcp: 404\n  /mcp/tools: 404\n  /mcp/message: 404\n  /sse: 200 OK\n  /api: 404\n\nCreated client for server at http://localhost:4242/sse\nClient message path: http://localhost:4242/sse\n\nTesting MCP Client...\n\n1. Listing available tools:\n  - name='say_hello' description='Greet a person by name.' inputSchema={...}\n  - name='get_greeting_log' description='Get a list of all greeted names.' inputSchema={...}\n  - name='clear_log' description='Clear the greeting history.' inputSchema={...}\n\n2. Testing say_hello tool:\n  Result: [TextContent(type='text', text='{\"message\": \"Hello, Alice!\"}', annotations=None)]\n\n3. Testing get_greeting_log tool:\n  Result: [TextContent(type='text', text='{\"names\": [\"Alice\"]}', annotations=None)]\n\n4. Testing greeting log resource:\n  Resource: [TextResourceContents(uri=AnyUrl('greetings://log'), mimeType='text/plain', text='{\"greeted_names\": [\"Alice\"]}')]\n\n5. Testing clear_log tool:\n  Result: [TextContent(type='text', text='{\"status\": \"cleared\"}', annotations=None)]\n\n6. Verifying log is cleared:\n  Result: [TextContent(type='text', text='{\"names\": []}', annotations=None)]\n\n7. Listing available prompts:\n  - name='greet_user' description='Create a prompt for greeting someone.' arguments=[...]\n\n8. Testing greet_user prompt:\n  Prompt: [PromptMessage(role='user', content=TextContent(type='text', text='\\n    Use the `say_hello` tool to greet Bob...')]\n```\n\nKey observations:\n- Only the `/sse` endpoint returns a 200 status code - this is normal and expected\n- Tool results come back as `TextContent` objects with JSON payloads\n- Resources are returned as `TextResourceContents` objects with URIs and content\n- The greeting log stores and clears names correctly\n- The prompt template generates a user message with instructions\n\nThe test client source (`test_client.py`) is commented and can be used as a reference for building your own MCP clients.\n\n### Using the Python MCP Client\n\n```python\nimport asyncio\nfrom fastmcp import Client\n\nasync def main():\n    async with Client(\"http://localhost:4242/sse\") as client:\n        # List available tools\n        tools = await client.list_tools()\n        print(tools)\n        \n        # Call a tool\n        result = await client.call_tool(\"say_hello\", {\"name\": \"Alice\"})\n        print(result)\n\nasyncio.run(main())\n```\n\n### Using curl\n\nDirect HTTP REST API calls are not supported. FastMCP uses a WebSocket-based protocol for client-server communication through Server-Sent Events (SSE).\n\n## Implementation Details\n\nThis server demonstrates:\n\n1. **Decorator-based API**: Using decorators for tools, resources, and prompts\n2. **Shared State**: Maintaining state between requests using the GreetingLog\n3. **SSE Transport**: Using FastMCP's SSE transport for client communication\n4. **Uvicorn Integration**: Running as a production-ready ASGI server with Uvicorn\n\nThe server can run in two modes:\n- **Uvicorn mode** (default): Uses Uvicorn's ASGI server for better performance and production readiness\n- **Built-in mode**: Uses FastMCP's built-in server for simplicity\n\n## Architecture\n\n### Main Components\n\nThis project follows a modular architecture:\n\n1. **main.py**: The core server definition with:\n   - FastMCP setup and configuration\n   - Tool, resource, and prompt definitions\n   - ASGI app initialization for Uvicorn\n   - Flexible runner that supports both Uvicorn and built-in modes\n\n2. **setup_and_run.sh**: Deployment script with:\n   - Environment setup\n   - Port conflict detection\n   - Configurable runtime options\n   - Background/foreground process management\n\n3. **test_client.py**: Client implementation that demonstrates:\n   - Endpoint discovery\n   - MCP client connection\n   - Tool and resource interaction\n\n### Uvicorn Integration Code\n\nThe key to the Uvicorn integration is in `main.py`:\n\n```python\n# Create the ASGI app for Uvicorn to use\napp = mcp.sse_app()\n\ndef run_server(use_uvicorn=True, host=\"0.0.0.0\", port=4242):\n    \"\"\"Run the server using either Uvicorn or built-in transport.\"\"\"\n    if use_uvicorn:\n        print(f\"Starting server with Uvicorn on {host}:{port}\")\n        uvicorn.run(\n            \"main:app\",\n            host=host,\n            port=port,\n            log_level=\"info\"\n        )\n    else:\n        print(f\"Starting server with built-in transport on port {port}\")\n        mcp.run(transport=\"sse\", host=host, port=port)\n```\n\n## Debugging Tips\n\n1. Server logs are saved to `server.log`\n2. Run in foreground mode for immediate feedback: `./setup_and_run.sh --foreground`\n3. The FastMCP client connects to the `/sse` endpoint, not directly to tool paths\n4. Data is exchanged via a message-based protocol, not standard REST\n5. You can identify which mode the server is running in by checking the logs:\n   - Uvicorn mode: \"INFO: Uvicorn running on http://0.0.0.0:PORT\"\n   - Built-in mode: \"INFO: Starting server 'Hello World MCP Server'...\"\n\nHere's an updated section that includes both configuration options:\n\n## Claude Desktop Integration\n\nTo configure Claude Desktop to use this MCP server, add one of the following configurations to your Claude Desktop configuration file:\n\n- Windows: `%AppData%\\Claude\\claude_desktop_config.json`\n- Mac: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n### Option 1: Let Claude Desktop start the server\n\n```json\n{\n  \"mcpServers\": {\n    \"hello-world\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"main\",\n        \"--uvicorn\"\n      ],\n      \"env\": {},\n      \"cwd\": \"/path/to/your/hello-world-mcp-server\"\n    }\n  }\n}\n```\n\n### Option 2: Connect to an already running server\n\nIf you've already started the server manually using `./setup_and_run.sh`:\n\n```json\n{\n  \"mcpServers\": {\n    \"hello-world\": {\n      \"url\": \"http://localhost:4242/sse\"\n    }\n  }\n}\n```\n\nAfter saving the configuration, restart Claude Desktop. You should see the hammer icon indicating MCP server availability. Click it to access the Hello World MCP tools.\n\n## Learn More\n\nFor more information about MCP, see:\n- [FastMCP Documentation](https://github.com/anthropics/fastmcp)\n- [MCP Specification](https://github.com/anthropics/anthropic-tools/blob/main/specs/mcp.md)\n- [Uvicorn Documentation](https://www.uvicorn.org/)\n- [ASGI Specification](https://asgi.readthedocs.io/en/latest/) "
}