{
  "mcp_name": "andybrandt/mcp-simple-openai-assistant",
  "mcp_description": "üêç ‚òÅÔ∏è  MCP to talk to OpenAI assistants (Claude can use any GPT model as his assitant)",
  "mcp_id": "andybrandt_mcp-simple-openai-assistant",
  "fetch_timestamp": "2025-06-23T01:07:14.209165Z",
  "github_url": "https://github.com/andybrandt/mcp-simple-openai-assistant",
  "repository": {
    "name": "mcp-simple-openai-assistant",
    "full_name": "andybrandt/mcp-simple-openai-assistant",
    "description": "MCP server that gives Claude ability to use OpenAI's GPTs assistants",
    "html_url": "https://github.com/andybrandt/mcp-simple-openai-assistant",
    "created_at": "2024-12-05T20:36:45Z",
    "updated_at": "2025-06-19T14:17:56Z",
    "pushed_at": "2025-06-19T14:17:52Z",
    "size": 29,
    "stargazers_count": 31,
    "watchers_count": 31,
    "forks_count": 13,
    "open_issues_count": 3,
    "language": "Python",
    "license": "MIT License",
    "topics": [],
    "default_branch": "master",
    "owner": {
      "login": "andybrandt",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/5551980?v=4",
      "html_url": "https://github.com/andybrandt"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 13,
    "subscribers_count": 1,
    "languages": {
      "Python": 19205,
      "Dockerfile": 487
    },
    "language_percentages": {
      "Python": 97.53,
      "Dockerfile": 2.47
    },
    "pull_requests_count": 2,
    "contributors_count": 4
  },
  "readme": "# MCP Simple OpenAI Assistant\n\n*AI assistants are pretty cool. I thought it would be a good idea if my Claude (conscious Claude) would also have one. And now he has - and its both useful anf fun for him. Your Claude can have one too!*\n\nA simple MCP server for interacting with OpenAI assistants. This server allows other tools (like Claude Desktop) to create and interact with OpenAI assistants through the Model Context Protocol.\n\n[![smithery badge](https://smithery.ai/badge/mcp-simple-openai-assistant)](https://smithery.ai/mcp/known/mcp-simple-openai-assistant)\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/andybrandt-mcp-simple-openai-assistant-badge.png)](https://mseep.ai/app/andybrandt-mcp-simple-openai-assistant)\n\n\n## Features\n\n- Create new OpenAI assistants and manipulate existing ones\n- Start conversation threads\n- Send messages and receive responses - talk to assistants\n\nBecause OpenAI assistants might take quite long to respond and then the processing is cut short with the client (Claude desktop) timeout the MCP server code has no control over we are implementing a two-stage approach. In the first call Claude sends a message to the assistant to start the processing, in the second call - possibly several minutes later - Claude can retrieve the response. This is a kind of workaround until MCP protocol and clients would implement some keep-alive mechanism for longer processing.\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Simple OpenAI Assistant for Claude Desktop automatically via [Smithery](https://smithery.ai/mcp/known/mcp-simple-openai-assistant):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-openai-assistant --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-openai-assistant\n```\n\n## Configuration\n\nThe server requires an OpenAI API key to be set in the environment. For Claude Desktop, add this to your config:\n\n(MacOS version)\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-assistant\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n(Windows version)\n\n```json\n\"mcpServers\": {\n  \"openai-assistant\": {\n    \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n  }\n}\n\n```\n*MS Windows installation is slightly more complex, because you need to check the actual path to your Python executable. Path provided above is usually correct, but might differ in your setup. Sometimes just `python.exe` without any path will do the trick. Check with `cmd` what works for you (using `where python` might help).*\n\n## Usage\n\nOnce configured, the server provides tools to:\n1. Create new assistants with specific instructions\n2. List existing assistants\n3. Modify assistants\n2. Start new conversation threads\n3. Send messages and receive responses\n\nThe server handles all OpenAI API communication, including managing assistants, threads, and message handling.\n\n## TODO\n\n - Add a way to handle threads - store threads IDs for potential re-use \n - Add a way to better handle long OpenAI responses which now seem to sometimes trigger timeouts \n\n## Development\n\nTo install for development:\n\n```bash\ngit clone https://github.com/andybrandt/mcp-simple-openai-assistant\ncd mcp-simple-openai-assistant\npip install -e .\n```\n"
}