{
  "mcp_name": "ZenML",
  "mcp_description": "üêç üè† ‚òÅÔ∏è - An MCP server to connect with your [ZenML](https://www.zenml.io) MLOps and LLMOps pipelines",
  "mcp_id": "zenml-io_mcp-zenml",
  "fetch_timestamp": "2025-06-23T09:45:44.704283Z",
  "github_url": "https://github.com/zenml-io/mcp-zenml",
  "repository": {
    "name": "mcp-zenml",
    "full_name": "zenml-io/mcp-zenml",
    "description": "MCP server to connect an MCP client (Cursor, Claude Desktop etc) with your ZenML MLOps and LLMOps pipelines",
    "html_url": "https://github.com/zenml-io/mcp-zenml",
    "created_at": "2025-02-22T15:49:15Z",
    "updated_at": "2025-06-23T05:55:16Z",
    "pushed_at": "2025-06-23T05:55:14Z",
    "size": 590,
    "stargazers_count": 18,
    "watchers_count": 18,
    "forks_count": 8,
    "open_issues_count": 3,
    "language": "Python",
    "license": null,
    "topics": [
      "llmops",
      "mcp",
      "mcp-server",
      "mlops"
    ],
    "default_branch": "main",
    "owner": {
      "login": "zenml-io",
      "type": "Organization",
      "avatar_url": "https://avatars.githubusercontent.com/u/88676955?v=4",
      "html_url": "https://github.com/zenml-io"
    },
    "has_issues": true,
    "has_projects": false,
    "has_downloads": true,
    "has_wiki": false,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 8,
    "subscribers_count": 3,
    "languages": {
      "Python": 42153,
      "Shell": 454
    },
    "language_percentages": {
      "Python": 98.93,
      "Shell": 1.07
    },
    "pull_requests_count": 4,
    "contributors_count": 1
  },
  "readme": "# MCP Server for ZenML\n\nThis project implements a [Model Context Protocol\n(MCP)](https://modelcontextprotocol.io/introduction) server for interacting with\nthe [ZenML](https://zenml.io) API.\n\n![ZenML MCP Server](assets/mcp-zenml.png)\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) is an open protocol that standardizes how\napplications provide context to Large Language Models (LLMs). It acts like a\n\"USB-C port for AI applications\" - providing a standardized way to connect AI\nmodels to different data sources and tools.\n\nMCP follows a client-server architecture where:\n- **MCP Hosts**: Programs like Claude Desktop or IDEs that want to access data through MCP\n- **MCP Clients**: Protocol clients that maintain 1:1 connections with servers\n- **MCP Servers**: Lightweight programs that expose specific capabilities through the standardized protocol\n- **Local Data Sources**: Your computer's files, databases, and services that MCP servers can securely access\n- **Remote Services**: External systems available over the internet that MCP servers can connect to\n\n## What is ZenML?\n\nZenML is an open-source platform for building and managing ML and AI pipelines.\nIt provides a unified interface for managing data, models, and experiments.\n\nFor more information, see the [ZenML website](https://zenml.io) and [our documentation](https://docs.zenml.io).\n\n## Features\n\nThe server provides MCP tools to access core read functionality from the ZenML\nserver, providing a way to get live information about:\n\n- Users\n- Stacks\n- Pipelines\n- Pipeline runs\n- Pipeline steps\n- Services\n- Stack components\n- Flavors\n- Pipeline run templates\n- Schedules\n- Artifacts (metadata about data artifacts, not the data itself)\n- Service Connectors\n- Step code\n- Step logs (if the step was run on a cloud-based stack)\n\nIt also allows you to trigger new pipeline runs (if a run template is present).\n\n*Note: This is a beta/experimental release. We're still exploring how people\nwill use this integration, so we welcome your feedback and suggestions! Please\njoin our [Slack community](https://zenml.io/slack) to share your experience and\nhelp us improve.*\n\n## Testing & Quality Assurance\n\nThis project includes automated testing to ensure the MCP server remains functional:\n\n- **üîÑ Automated Smoke Tests**: A comprehensive smoke test runs every 3 days via GitHub Actions\n- **üö® Issue Creation**: Failed tests automatically create GitHub issues with detailed debugging information\n- **‚ö° Fast CI**: Uses UV with caching for quick dependency installation and testing\n- **üß™ Manual Testing**: You can run the smoke test locally using `uv run scripts/test_mcp_server.py zenml_server.py`\n\nThe automated tests verify:\n- MCP protocol connection and handshake\n- Server initialization and tool discovery  \n- Basic tool functionality (when ZenML server is accessible)\n- Resource and prompt enumeration\n\n## How to use\n\n### Prerequisites\n\nYou will need to have access to a deployed ZenML server. If you don't have one,\nyou can sign up for a free trial at [ZenML Pro](https://cloud.zenml.io) and we'll manage the deployment for you.\n\nYou will also (probably) need to have `uv` installed locally. For more information, see\nthe [`uv` documentation](https://docs.astral.sh/uv/getting-started/installation/).\nWe recommend installation via their installer script or via `brew` if using a\nMac. (Technically you don't *need* it, but it makes installation and setup easy.)\n\nYou will also need to clone this repository somewhere locally:\n\n```bash\ngit clone https://github.com/zenml-io/mcp-zenml.git\n```\n\n### Your MCP config file\n\nThe MCP config file is a JSON file that tells the MCP client how to connect to\nyour MCP server. Different MCP clients will use or specify this differently. Two\ncommonly-used MCP clients are [Claude Desktop](https://claude.ai/download) and\n[Cursor](https://www.cursor.com/), for which we provide installation instructions\nbelow.\n\nYou will need to specify your ZenML MCP server in the following format:\n\n```json\n{\n    \"mcpServers\": {\n        \"zenml\": {\n            \"command\": \"/usr/local/bin/uv\",\n            \"args\": [\"run\", \"path/to/zenml_server.py\"],\n            \"env\": {\n                \"LOGLEVEL\": \"INFO\",\n                \"NO_COLOR\": \"1\",\n                \"PYTHONUNBUFFERED\": \"1\",\n                \"PYTHONIOENCODING\": \"UTF-8\",\n                \"ZENML_STORE_URL\": \"https://your-zenml-server-goes-here.com\",\n                \"ZENML_STORE_API_KEY\": \"your-api-key-here\"\n            }\n        }\n    }\n}\n```\n\nThere are four dummy values that you will need to replace:\n\n- the path to your locally installed `uv` (the path listed above is where it\n  would be on a Mac if you installed it via `brew`)\n- the path to the `zenml_server.py` file (this is the file that will be run when\n  you connect to the MCP server). This file is located inside this repository at\n  the root. You will need to specify the exact full path to this file.\n- the ZenML server URL (this is the URL of your ZenML server. You can find this\n  in the ZenML Cloud UI). It will look something like `https://d534d987a-zenml.cloudinfra.zenml.io`.\n- the ZenML server API key (this is the API key for your ZenML server. You can\n  find this in the ZenML Cloud UI or [read these\n  docs](https://docs.zenml.io/how-to/manage-zenml-server/connecting-to-zenml/connect-with-a-service-account)\n  on how to create one. For the purposes of the ZenML MCP server we recommend\n  using a service account.)\n\nYou are free to change the way you run the MCP server Python file, but using\n`uv` will probably be the easiest option since it handles the environment and\ndependency installation for you.\n\n\n### Installation for use with Claude Desktop\n\nYou will need to have [Claude Desktop](https://claude.ai/download) installed.\n\nOnce you have installed and opened Claude Desktop, you need to open the\n'Settings' menu and click on the 'Developer' tab. There will be an 'Edit Config'\nbutton which will open up a file explorer showing you the location of your\nconfig file.\n\nYou should paste the contents of the (properly filled in) config file above into\nthe JSON file revealed in the file explorer. Then just restart Claude Desktop\nand it will use the new config. You should be able to see the ZenML server in\nthe developer settings menu. Chat with Claude and it will use all the new tools\nyou just gave it access to.\n\n#### Optional: Improving ZenML Tool Output Display\n\nFor a better experience with ZenML tool results, you can configure Claude to\ndisplay the JSON responses in a more readable format. In Claude Desktop, go to\nSettings ‚Üí Profile, and in the \"What personal preferences should Claude consider\nin responses?\" section, add something like the following (or use these exact\nwords!):\n\n```markdown\nWhen using zenml tools which return JSON strings and you're asked a question, you might want to consider using markdown tables to summarize the results or make them easier to view!\n```\n\nThis will encourage Claude to format ZenML tool outputs as markdown tables,\nmaking the information much easier to read and understand.\n\n### Installation for use with Cursor\n\nYou will need to have [Cursor](https://www.cursor.com/) installed.\n\nCursor works slightly differently to Claude Desktop in that you specify the\nconfig file on a per-repository basis. This means that if you want to use the\nZenML MCP server in multiple repos, you will need to specify the config file in\neach of them.\n\nTo set it up for a single repository, you will need to:\n\n- create a `.cursor` folder in the root of your repository\n- inside it, create a `mcp.json` file with the content above\n- go into your Cursor settings and click on the ZenML server to 'enable' it.\n\nIn our experience, sometimes it shows a red error indicator even though it is\nworking. You can try it out by chatting in the Cursor chat window. It will let\nyou know if is able to access the ZenML tools or not.\n"
}