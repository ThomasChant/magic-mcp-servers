{
  "mcp_name": "shifusen329/doc-lib-mcp",
  "mcp_description": "Facilitates document ingestion, chunking, semantic search, and note management with a custom URI scheme and robust content extraction tools.",
  "mcp_id": "shifusen329_doc-lib-mcp",
  "fetch_timestamp": "2025-06-23T08:24:09.404280Z",
  "github_url": "https://github.com/shifusen329/doc-lib-mcp",
  "repository": {
    "name": "doc-lib-mcp",
    "full_name": "shifusen329/doc-lib-mcp",
    "description": null,
    "html_url": "https://github.com/shifusen329/doc-lib-mcp",
    "created_at": "2025-04-23T07:27:30Z",
    "updated_at": "2025-05-19T07:06:54Z",
    "pushed_at": "2025-05-19T07:06:50Z",
    "size": 81,
    "stargazers_count": 0,
    "watchers_count": 0,
    "forks_count": 1,
    "open_issues_count": 1,
    "language": "Python",
    "license": null,
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "shifusen329",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/180048343?v=4",
      "html_url": "https://github.com/shifusen329"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 1,
    "subscribers_count": 1,
    "languages": {
      "Python": 37330
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 1,
    "contributors_count": 1
  },
  "readme": "# doc-lib-mcp MCP server\n\nA Model Context Protocol (MCP) server for document ingestion, chunking, semantic search, and note management.\n\n## Components\n\n### Resources\n\n- Implements a simple note storage system with:\n  - Custom `note://` URI scheme for accessing individual notes\n  - Each note resource has a name, description, and `text/plain` mimetype\n\n### Prompts\n\n- Provides a prompt:\n  - **summarize-notes**: Creates summaries of all stored notes\n    - Optional \"style\" argument to control detail level (brief/detailed)\n    - Generates prompt combining all current notes with style preference\n\n### Tools\n\nThe server implements a wide range of tools:\n\n- **add-note**: Add a new note to the in-memory note store\n  - Arguments: `name` (string), `content` (string)\n- **ingest-string**: Ingest and chunk a markdown or plain text string provided via message\n  - Arguments: `content` (string, required), `source` (string, optional), `tags` (list of strings, optional)\n- **ingest-markdown**: Ingest and chunk a markdown (.md) file\n  - Arguments: `path` (string)\n- **ingest-python**: Ingest and chunk a Python (.py) file\n  - Arguments: `path` (string)\n- **ingest-openapi**: Ingest and chunk an OpenAPI JSON file\n  - Arguments: `path` (string)\n- **ingest-html**: Ingest and chunk an HTML file\n  - Arguments: `path` (string)\n- **ingest-html-url**: Ingest and chunk HTML content from a URL (optionally using Playwright for dynamic content)\n  - Arguments: `url` (string), `dynamic` (boolean, optional)\n- **smart_ingestion**: Extracts all technically relevant content from a file using Gemini, then chunks it using robust markdown logic.\n  - Arguments:\n    - `path` (string, required): File path to ingest.\n    - `prompt` (string, optional): Custom prompt to use for Gemini.\n    - `tags` (list of strings, optional): Optional list of tags for classification.\n  - Uses Gemini 2.0 Flash 001 to extract only code, configuration, markdown structure, and technical definitions (no summaries or commentary).\n  - Passes the extracted content to a mistune 3.x-based chunker that preserves both code blocks and markdown/narrative content as separate chunks.\n  - Each chunk is embedded and stored for semantic search and retrieval.\n- **search-chunks**: Semantic search over ingested content\n  - Arguments:\n    - `query` (string): The semantic search query.\n    - `top_k` (integer, optional, default 3): Number of top results to return.\n    - `type` (string, optional): Filter results by chunk type (e.g., `code`, `html`, `markdown`).\n    - `tag` (string, optional): Filter results by tag in chunk metadata.\n  - Returns the most relevant chunks for a given query, optionally filtered by type and/or tag.\n- **delete-source**: Delete all chunks from a given source\n  - Arguments: `source` (string)\n- **delete-chunk-by-id**: Delete one or more chunks by id\n  - Arguments: `id` (integer, optional), `ids` (list of integers, optional)\n  - You can delete a single chunk by specifying `id`, or delete multiple chunks at once by specifying `ids`.\n- **update-chunk-type**: Update the type attribute for a chunk by id\n  - Arguments: `id` (integer, required), `type` (string, required)\n- **ingest-batch**: Ingest and chunk multiple documentation files (markdown, OpenAPI JSON, Python) in batch\n  - Arguments: `paths` (list of strings)\n- **list-sources**: List all unique sources (file paths) that have been ingested and stored in memory, with optional filtering by tag or semantic search.\n  - Arguments:\n    - `tag` (string, optional): Filter sources by tag in chunk metadata.\n    - `query` (string, optional): Semantic search query to find relevant sources.\n    - `top_k` (integer, optional, default 10): Number of top sources to return when using query.\n- **get-context**: Retrieve relevant content chunks (content only) for use as AI context, with filtering by tag, type, and semantic similarity.\n  - Arguments:\n    - `query` (string, optional): The semantic search query.\n    - `tag` (string, optional): Filter results by a specific tag in chunk metadata.\n    - `type` (string, optional): Filter results by chunk type (e.g., 'code', 'markdown').\n    - `top_k` (integer, optional, default 5): The number of top relevant chunks to retrieve.\n- **update-chunk-metadata**: Update the metadata field for a chunk by id\n  - Arguments: `id` (integer), `metadata` (object)\n- **tag-chunks-by-source**: Adds specified tags to the metadata of all chunks associated with a given source (URL or file path). Merges with existing tags.\n  - Arguments: `source` (string), `tags` (list of strings)\n- **list-notes**: List all currently stored notes and their content.\n\n#### Chunking and Code Extraction\n\n- Markdown, Python, OpenAPI, and HTML files are split into logical chunks for efficient retrieval and search.\n- The markdown chunker uses mistune 3.x's AST API and regex to robustly split content by code blocks and narrative, preserving all original formatting.\n- Both code blocks and markdown/narrative content are preserved as separate chunks.\n- The HTML chunker uses the `readability-lxml` library to extract main content first, then extracts block code snippets from `<pre>` tags as dedicated \"code\" chunks. Inline `<code>` content remains part of the narrative chunks.\n\n#### Semantic Search\n\n- The `search-chunks` tool performs vector-based semantic search over all ingested content, returning the most relevant chunks for a given query.\n- Supports optional `type` and `tag` arguments to filter results by chunk type (e.g., `code`, `html`, `markdown`) and/or by tag in chunk metadata, before semantic ranking.\n- This enables highly targeted retrieval, such as \"all code chunks tagged with 'langfuse' relevant to 'cost and usage'\".\n\n#### Metadata Management\n\n- Chunks include a `metadata` field for categorization and tagging.\n- The `update-chunk-metadata` tool allows updating metadata for any chunk by its id.\n- The `tag-chunks-by-source` tool allows adding tags to all chunks from a specific source in one operation. Tagging merges new tags with existing ones, preserving previous tags.\n\n## Configuration\n\nThe server requires the following environment variables (can be set in a .env file):\n\n### Ollama Configuration\n- OLLAMA_HOST: Hostname for Ollama API (default: localhost)\n- OLLAMA_PORT: Port for Ollama API (default: 11434)\n- RAG_AGENT: Ollama model to use for RAG responses (default: llama3)\n- OLLAMA_MODEL: Ollama model to use for embeddings (default: nomic-embed-text-v2-moe)\n\n### Database Configuration\n- HOST: PostgreSQL database host (default: localhost)\n- DB_PORT: PostgreSQL database port (default: 5432)\n- DB_NAME: PostgreSQL database name (default: doclibdb)\n- DB_USER: PostgreSQL database user (default: doclibdb_user)\n- DB_PASSWORD: PostgreSQL database password (default: doclibdb_password)\n\n### Reranker Configuration\n- RERANKER_MODEL_PATH: Path to the reranker model (default: /srv/samba/fileshare2/AI/models/bge-reranker-v2-m3)\n- RERANKER_USE_FP16: Whether to use FP16 for reranker (default: True)\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"doc-lib-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/home/administrator/python-share/doc-lib-mcp\",\n        \"run\",\n        \"doc-lib-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"doc-lib-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"doc-lib-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /home/administrator/python-share/doc-lib-mcp run doc-lib-mcp\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n"
}