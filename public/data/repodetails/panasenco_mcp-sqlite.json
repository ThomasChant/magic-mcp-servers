{
  "mcp_name": "SQLite",
  "mcp_description": "MCP server for SQLite files. Supports Datasette-compatible metadata!",
  "mcp_id": "panasenco_mcp-sqlite",
  "fetch_timestamp": "2025-06-23T08:35:01.026416Z",
  "github_url": "https://github.com/panasenco/mcp-sqlite",
  "repository": {
    "name": "mcp-sqlite",
    "full_name": "panasenco/mcp-sqlite",
    "description": "MCP server for SQLite files. Supports Datasette-compatible metadata!",
    "html_url": "https://github.com/panasenco/mcp-sqlite",
    "created_at": "2025-05-31T03:26:48Z",
    "updated_at": "2025-06-21T17:57:07Z",
    "pushed_at": "2025-06-06T19:36:09Z",
    "size": 548,
    "stargazers_count": 7,
    "watchers_count": 7,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": "Apache License 2.0",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "panasenco",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/5506411?v=4",
      "html_url": "https://github.com/panasenco"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 0,
    "languages": {
      "Python": 26161
    },
    "language_percentages": {
      "Python": 100
    },
    "pull_requests_count": 0,
    "contributors_count": 1,
    "tags": [
      {
        "name": "v0.1.0-rc.1",
        "commit_sha": "b3e5a60fe61a5b05dacd390b3b9e385ebe52dde9"
      },
      {
        "name": "0.1.3",
        "commit_sha": "4c43aac1964db1de47633f162dcde9942edd9266"
      },
      {
        "name": "0.1.3rc1",
        "commit_sha": "1eba7ed5f1def9691c704fd05ab95086a4131180"
      },
      {
        "name": "0.1.2",
        "commit_sha": "3e9f2f868e9929b82458a075e403606d55ad80c1"
      },
      {
        "name": "0.1.1",
        "commit_sha": "8f11f989d21528b81427ce73333fee0657e3c25c"
      },
      {
        "name": "0.1.1rc1",
        "commit_sha": "afdbbfd1efdae8ced1bee14bbd6b4a1d9920f22c"
      },
      {
        "name": "0.1.0",
        "commit_sha": "cc3332c593d38a2c8fc2d644d7484cd07be9be1f"
      },
      {
        "name": "0.1.0rc2",
        "commit_sha": "1914cf2727214f9ea67ea4d40a896ec9205aa1ed"
      }
    ],
    "latest_version": "v0.1.0-rc.1"
  },
  "readme": "# mcp-sqlite\n<p align=\"center\">\n  <img src=\"https://github.com/panasenco/mcp-sqlite/raw/main/images/mcp-sqlite-256.png\">\n</p>\n\nProvide useful data to AI agents without giving them access to external systems. Compatible with Datasette for human users!\n\n## Features\n- AI agents can get the structure of all tables and columns in the SQLite database in one command - `sqlite_get_catalog`.\n  - The catalog can be enriched with descriptions for the tables and columns using a simple YAML or JSON metadata file.\n- The same metadata file can contain canned queries to the AI to use.\n  Each canned query will be turned into a separate MCP tool `sqlite_execute_main_{tool name}`.\n- AI agents can execute arbitrary SQL queries with `sqlite_execute`.\n\n\n## Quickstart\n1.  Install [uv](https://docs.astral.sh/uv/getting-started/installation/).\n2.  Download the sample SQLite database [titanic.db](https://github.com/davidjamesknight/SQLite_databases_for_learning_data_science/raw/refs/heads/main/titanic.db).\n3.  Create a metadata file `titanic.yml` for your dataset:\n    ```yaml\n    databases:\n      titanic:\n        tables:\n          Observation:\n            description: Main table connecting passenger attributes to observed outcomes.\n            columns:\n              survived: \"0/1 indicator whether the passenger survived.\"\n              age: The passenger's age at the time of the crash.\n              # Other columns are not documented but are still visible to the AI agent\n        queries:\n          survivors_of_age:\n            title: Count survivors of a specific age\n            description: Returns the total counts of passengers and survivors, both for all ages and for a specific provided age.\n            sql: |-\n              select\n                count(*) as total_passengers,\n                sum(survived) as survived_passengers,\n                sum(case when age = :age then 1 else 0 end) as total_specific_age,\n                sum(case when age = :age and survived = 1 then 1 else 0 end) as survived_specific_age\n              from Observation\n    ```\n4.  Create an entry in your MCP client for your database and metadata\n    ```json\n    {\n        \"mcpServers\": {\n            \"sqlite\": {\n                \"command\": \"uvx\",\n                \"args\": [\n                    \"mcp-sqlite\",\n                    \"/absolute/path/to/titanic.db\",\n                    \"--metadata\",\n                    \"/absolute/path/to/titanic.yml\"\n                ]\n            }\n        }\n    }\n    ```\n\nYour AI agent should now be able to use mcp-sqlite tools `sqlite_get_catalog`, `sqlite_execute`, and `sqlite_execute_main_survivors_of_age`!\n\n## Interactive exploration with MCP Inspector and Datasette\n\nThe same database and metadata files can be used to explore the data interactively with MCP Inspector and Datasette.\n\n| MCP Inspector | Datasette |\n| ------------- | --------- |\n| ![](https://github.com/panasenco/mcp-sqlite/raw/main/images/mcp-inspector-sqlite-get-catalog.png) | ![](https://github.com/panasenco/mcp-sqlite/raw/main/images/datasette-table-view.png) |\n| ![](https://github.com/panasenco/mcp-sqlite/raw/main/images/mcp-inspector-sqlite-canned-query-tool.png) | ![](https://github.com/panasenco/mcp-sqlite/raw/main/images/datasette-canned-query.png) |\n\n### MCP Inspector\nUse the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) dashboard to interact with the SQLite database the same way that an AI agent would:\n1.  Install [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n2.  Run:\n    ```\n    npx @modelcontextprotocol/inspector uvx mcp-sqlite path/to/titanic.db --metadata path/to/titanic.yml\n    ```\n\n### Datasette\nSince `mcp-sqlite` metadata is compatible with the Datasette metadata file, you can also explore your data with Datasette:\n```\nuvx datasette serve path/to/titanic.db --metadata path/to/titanic.yml\n```\nCompatibility with Datasette allows both AI agents and humans to easily explore the same local data!\n\n\n## MCP Tools provided by mcp-sqlite\n- **sqlite_get_catalog()**: Tool the agent can call to get the complete catalog of the databases, tables, and columns in the data, combined with metadata from the metadata file.\n  In an earlier iteration of `mcp-sqlite`, this was a resource instead of a tool, but resources are not as widely supported, so it got turned into a tool.\n  If you have a usecase for the catalog as a resource, open an issue and we'll bring it back!\n- **sqlite_execute(sql)**: Tool the agent can call to execute arbitrary SQL. The table results are returned as HTML.\n  For more information about why HTML is the best format for LLMs to process, see [Siu et al](https://arxiv.org/abs/2305.13062).\n- **sqlite_execute_main_{canned query name}({canned query args})**: A tool is created for each canned query in the metadata, allowing the agent to run predefined queries without writing any SQL.\n\n\n## Usage\n\n### Command-line options\n```\nusage: mcp-sqlite [-h] [-m METADATA] [-w] [-v] sqlite_file\n\nCLI command to start an MCP server for interacting with SQLite data.\n\npositional arguments:\n  sqlite_file           Path to SQLite file to serve the MCP server for.\n\noptions:\n  -h, --help            show this help message and exit\n  -m METADATA, --metadata METADATA\n                        Path to Datasette-compatible metadata YAML or JSON file.\n  -w, --write           Set this flag to allow the AI agent to write to the database. By default the database is opened in read-only mode.\n  -v, --verbose         Be verbose. Include once for INFO output, twice for DEBUG output.\n```\n\n### Metadata\n\n#### Hidden tables\n[Hiding a table](https://docs.datasette.io/en/stable/metadata.html#hiding-tables) with `hidden: true` will hide it from the catalog returned by the MCP tool `sqlite_get_catalog()`.\nHowever, note that the table will still be accessible by the AI agent!\nNever rely on hiding a table from the catalog as a security feature.\n\n#### Canned queries\n[Canned queries](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) are each turned into a separate callable MCP tool by mcp-sqlite.\n\nFor example, a query named `my_canned_query` will become a tool `sqlite_execute_main_my_canned_query`.\n\nThe canned queries functionality is still in active development with more features planned for development soon:\n\n| Datasette canned query feature | Supported in mcp-sqlite? |\n| ------------------------------ | ------------------------ |\n| [Displayed in catalog](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ✅ |\n| [Executable](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ✅ |\n| [Titles](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ✅ |\n| [Descriptions](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ✅ |\n| [Parameters](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ✅ |\n| [Explicit parameters](https://docs.datasette.io/en/stable/sql_queries.html#canned-queries) | ❌ (planned) |\n| [Hide SQL](https://docs.datasette.io/en/stable/sql_queries.html#hide-sql) | ✅ |\n| [Fragments](https://docs.datasette.io/en/stable/sql_queries.html#fragment) | ❌ (not planned) |\n| [Write restrictions on canned queries](https://docs.datasette.io/en/stable/sql_queries.html#writable-canned-queries) | ❌ (planned) |\n| [Magic parameters](https://docs.datasette.io/en/stable/sql_queries.html#magic-parameters) | ❌ (not planned) |\n"
}