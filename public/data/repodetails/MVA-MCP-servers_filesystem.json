{
  "mcp_name": "MVA-MCP-servers/filesystem",
  "mcp_description": "Node.js server for advanced filesystem operations using Model Context Protocol, featuring smart file management and directory navigation.",
  "mcp_id": "MVA-MCP-servers_filesystem",
  "fetch_timestamp": "2025-06-23T06:57:10.999206Z",
  "github_url": "https://github.com/MVA-MCP-servers/filesystem",
  "repository": {
    "name": "filesystem",
    "full_name": "MVA-MCP-servers/filesystem",
    "description": null,
    "html_url": "https://github.com/MVA-MCP-servers/filesystem",
    "created_at": "2025-04-28T07:22:41Z",
    "updated_at": "2025-04-28T18:20:23Z",
    "pushed_at": "2025-04-28T18:20:18Z",
    "size": 6410,
    "stargazers_count": 0,
    "watchers_count": 0,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "TypeScript",
    "license": "MIT License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "MVA-MCP-servers",
      "type": "Organization",
      "avatar_url": "https://avatars.githubusercontent.com/u/209438525?v=4",
      "html_url": "https://github.com/MVA-MCP-servers"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "TypeScript": 136643,
      "JavaScript": 122512,
      "Batchfile": 4802,
      "Dockerfile": 567
    },
    "language_percentages": {
      "TypeScript": 51.66,
      "JavaScript": 46.31,
      "Batchfile": 1.82,
      "Dockerfile": 0.21
    },
    "pull_requests_count": 0,
    "contributors_count": 1,
    "package_json_version": "0.6.2"
  },
  "readme": "# Filesystem MCP Server\n\nNode.js server implementing Model Context Protocol (MCP) for filesystem operations.\n\n## Features\n\n- Advanced file operations:\n  - Standard read/write with size limits\n  - Streaming reads with position control\n  - Smart append with duplication prevention\n  - Automatic write optimization\n- Directory operations:\n  - Create/list/navigate directories\n  - Recursive directory tree view\n  - Depth-limited traversal\n- File management:\n  - Move files/directories\n  - Search with pattern matching\n  - Get detailed file metadata\n\n**Note**: The server will only allow operations within directories specified via `args`.\n\n## API\n\n### Resources\n\n- `file://system`: File system operations interface\n\n### Advanced Features\n\n#### Reading Strategy Selection\nChoose the appropriate reading method based on your needs:\n- Use `read_file` for small files (<1MB) to get complete content\n- Use `stream_read_file` for:\n  - Large files that exceed memory limits\n  - When you need only a specific portion of a file\n  - Reading from the end of files (logs, databases)\n  - Processing files in manageable chunks\n\n#### Negative Offset Reading\nThe `stream_read_file` tool supports negative offset values, allowing you to read from the end of files:\n- Offset `-N` means \"start reading N bytes from the end of file\"\n- Perfect for reading the most recent entries in log files\n- System automatically calculates the correct position in the file\n- If the absolute value of negative offset exceeds file size, reading starts from the beginning\n\n#### Write Optimization\nThe server automatically optimizes file writing operations based on:\n- Content size (large content uses smart_append)\n- File size (large files use smart_append)\n- File existence (new vs existing files)\n- Write intent (full vs partial overwrite)\n\n#### Content Completion Marker\nContent can include completion markers (\"// END_OF_CONTENT\") to indicate complete writes.\nThis helps the system automatically detect and handle incomplete content during writes.\n\n### Tools\n\n- **read_file**\n  - Read complete contents of a file\n  - Input: `path` (string)\n  - Reads complete file contents with UTF-8 encoding\n  - For files larger than 1MB, only the first 1MB is returned with a warning\n  - Best for smaller files where you need the complete content\n\n- **stream_read_file**\n  - Read large files with precise control over reading positions\n  - Perfect for:\n    - Processing large files in manageable chunks\n    - Extracting specific portions without loading entire file\n    - Reading from the end of files (like logs)\n    - Reading files too large for standard read_file\n  - Inputs:\n    - `path` (string): File to read\n    - `offset` (number, optional): Starting position in bytes (default: 0)\n      - Can be negative to read from end of file (e.g., -1000 reads last 1000 bytes)\n      - If abs(offset) exceeds file size, reads from beginning\n    - `limit` (number, optional): Maximum bytes to read\n    - `encoding` (string, optional): Character encoding (default: 'utf8')\n    - `chunkSize` (number, optional): Size of chunks for streaming (default: 512KB)\n  - Returns selected portion of the file with info about read size and position\n  - Examples:\n    - Read last 1000 bytes: `offset: -1000`\n    - Read specific section: `offset: 5000, limit: 2000`\n    - Read from end with limit: `offset: -5000, limit: 1000` (1000 bytes starting 5000 bytes from end)\n\n- **read_multiple_files**\n  - Read multiple files simultaneously\n  - Inputs:\n    - `paths` (string[]): Array of file paths\n    - `logLevel` (string, optional): Debug level ('debug', 'info', 'warn', 'error')\n  - Failed reads won't stop the entire operation\n  - For files larger than 1MB, only first 1MB is returned\n\n- **write_file**\n  - Create new file or overwrite existing (exercise caution with this)\n  - Inputs:\n    - `path` (string): File location\n    - `content` (string): File content\n  - With optimization enabled, may automatically select optimal write method\n  - Complete overwrite of existing files\n\n- **append_file**\n  - Append content to the end of a file (or create if doesn't exist)\n  - Inputs:\n    - `path` (string): File location\n    - `content` (string): Content to append\n  - Safer than write_file when you want to preserve existing content\n  - With optimization enabled, may use smart_append for large content\n\n- **smart_append_file**\n  - Intelligently append content without duplication\n  - Inputs:\n    - `path` (string): File location\n    - `content` (string): Content to append\n    - `chunkSize` (number, optional): Initial buffer size for overlap detection (default: 1024)\n    - `logLevel` (string, optional): Debug level ('debug', 'info', 'warn', 'error')\n  - Features:\n    - Detects overlapping content between file end and new content beginning\n    - Only appends non-overlapping content to avoid duplication\n    - Uses dynamic buffer sizing for reliable overlap detection\n    - Employs optimized algorithms (Rabin-Karp for large chunks)\n  - Perfect for:\n    - Resilient logging where writes may be interrupted\n    - Incremental data collection\n    - Ensuring content integrity during appends\n\n- **edit_file**\n  - Make selective edits using advanced pattern matching and formatting\n  - Features:\n    - Line-based and multi-line content matching\n    - Whitespace normalization with indentation preservation\n    - Multiple simultaneous edits with correct positioning\n    - Indentation style detection and preservation\n    - Git-style diff output with context\n    - Preview changes with dry run mode\n  - Inputs:\n    - `path` (string): File to edit\n    - `edits` (array): List of edit operations\n      - `oldText` (string): Text to search for (can be substring)\n      - `newText` (string): Text to replace with\n    - `dryRun` (boolean): Preview changes without applying (default: false)\n  - Returns detailed diff and match information for dry runs, otherwise applies changes\n  - Best Practice: Always use dryRun first to preview changes before applying them\n\n- **create_directory**\n  - Create new directory or ensure it exists\n  - Input: `path` (string)\n  - Creates parent directories if needed\n  - Succeeds silently if directory exists\n\n- **list_directory**\n  - List directory contents with [FILE] or [DIR] prefixes\n  - Inputs:\n    - `path` (string): Directory to list\n    - `maxDepth` (number, optional): Maximum depth for recursive listing (default: 3)\n    - `maxItems` (number, optional): Maximum items to return (default: 1000)\n\n- **move_file**\n  - Move or rename files and directories\n  - Inputs:\n    - `source` (string)\n    - `destination` (string)\n  - Fails if destination exists\n\n- **search_files**\n  - Recursively search for files/directories\n  - Inputs:\n    - `path` (string): Starting directory\n    - `pattern` (string): Search pattern\n    - `excludePatterns` (string[]): Exclude any patterns. Glob formats are supported.\n  - Case-insensitive matching\n  - Returns full paths to matches\n\n- **directory_tree**\n  - Get recursive tree view of files and directories as JSON structure\n  - Inputs:\n    - `path` (string): Starting directory\n    - `maxDepth` (number, optional): Maximum depth for tree (default: 5)\n    - `maxItems` (number, optional): Maximum items to return (default: 5000)\n  - Returns structured JSON with type, name, and children properties\n  - Files have no children array, directories always have children array\n\n- **get_file_info**\n  - Get detailed file/directory metadata\n  - Input: `path` (string)\n  - Returns:\n    - Size\n    - Creation time\n    - Modified time\n    - Access time\n    - Type (file/directory)\n    - Permissions\n\n- **list_allowed_directories**\n  - List all directories the server is allowed to access\n  - No input required\n  - Returns:\n    - Directories that this server can read/write from\n\n## Usage with Claude Desktop\nAdd this to your `claude_desktop_config.json`:\n\nNote: you can provide sandboxed directories to the server by mounting them to `/projects`. Adding the `ro` flag will make the directory readonly by the server.\n\n### Docker\nNote: all directories must be mounted to `/projects` by default.\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/Users/username/Desktop,dst=/projects/Desktop\",\n        \"--mount\", \"type=bind,src=/path/to/other/allowed/dir,dst=/projects/other/allowed/dir,ro\",\n        \"--mount\", \"type=bind,src=/path/to/file.txt,dst=/projects/path/to/file.txt\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    }\n  }\n}\n```\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-filesystem\",\n        \"/Users/username/Desktop\",\n        \"/path/to/other/allowed/dir\"\n      ]\n    }\n  }\n}\n```\n\n## Build\n\nDocker build:\n\n```bash\ndocker build -t mcp/filesystem -f src/filesystem/Dockerfile .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n"
}