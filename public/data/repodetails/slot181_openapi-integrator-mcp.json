{
  "mcp_name": "slot181/openapi-integrator-mcp",
  "mcp_description": "Facilitates high-quality image generation through OpenAI-compatible APIs, offering a standardized interface for specifying image parameters.",
  "mcp_id": "slot181_openapi-integrator-mcp",
  "fetch_timestamp": "2025-06-23T08:29:57.940533Z",
  "github_url": "https://github.com/slot181/openapi-integrator-mcp",
  "repository": {
    "name": "openapi-integrator-mcp",
    "full_name": "slot181/openapi-integrator-mcp",
    "description": null,
    "html_url": "https://github.com/slot181/openapi-integrator-mcp",
    "created_at": "2025-05-06T10:07:56Z",
    "updated_at": "2025-05-14T18:15:57Z",
    "pushed_at": "2025-05-14T18:15:53Z",
    "size": 149,
    "stargazers_count": 1,
    "watchers_count": 1,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "JavaScript",
    "license": "MIT License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "slot181",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/58209373?v=4",
      "html_url": "https://github.com/slot181"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "JavaScript": 90637,
      "TypeScript": 78102
    },
    "language_percentages": {
      "JavaScript": 53.71,
      "TypeScript": 46.29
    },
    "pull_requests_count": 0,
    "contributors_count": 1,
    "package_json_version": "2.1.8"
  },
  "readme": "# OpenAI Compatible API MCP Server (English)\n\nThis project is a Model Context Protocol (MCP) server that integrates various tools based on OpenAI compatible APIs and SiliconFlow APIs. It offers a range of functionalities including image generation, image editing, speech synthesis (TTS), speech-to-text (STT), and video generation.\n\n## Core Features\n\n-   **Image Generation**: Generate images using OpenAI compatible APIs (e.g., DALL-E 3, gpt-image-1, or other Stable Diffusion models).\n-   **Image Editing**: Edit images using OpenAI compatible APIs (e.g., gpt-image-1).\n-   **Speech Synthesis (TTS)**: Convert text into speech using OpenAI compatible APIs.\n-   **Speech-to-Text (STT)**: Transcribe audio files into text using OpenAI compatible APIs.\n-   **Video Generation**: Submit text-to-video or image-to-video generation tasks using the SiliconFlow API.\n-   **Background Task Processing**: For time-consuming tasks (like image generation/editing with specific models, video generation), the server accepts the task and processes it asynchronously. Notifications are sent via configured channels (OneBot or Telegram) upon completion or failure.\n-   **File Upload**: Supports uploading generated images and videos to a configured ImgBed service based on [MarSeventh/CloudFlare-ImgBed](https://github.com/MarSeventh/CloudFlare-ImgBed).\n-   **Local Storage**: All generated media files are saved locally.\n\n## Prerequisites\n\n-   Node.js (recommended version >= 18.x)\n-   Relevant API keys (OpenAI/compatible API key, SiliconFlow API key, etc.)\n\n## Installation and Setup\n\n1.  **Clone the project** (if you haven't already):\n    ```bash\n    git clone <project_repository_url>\n    cd openapi-integrator-mcp\n    ```\n\n2.  **Install dependencies**:\n    ```bash\n    npm install\n    ```\n\n3.  **Build the project**:\n    ```bash\n    npm run build\n    ```\n    The build output will be in the `build` directory.\n\n## Configuration\n\nConfigure environment variables via a `.env` file in the project root. If the `.env` file does not exist, create it based on `.env.example` (if provided) or the list below.\n\n### Key Environment Variables:\n\n-   `OPENAI_API_KEY`: (Required) Your OpenAI API key or a compatible API key.\n-   `OPENAI_API_BASE_URL`: (Optional) Base URL for the OpenAI compatible API. Defaults to `https://api.openai.com`.\n-   `REQUEST_TIMEOUT`: (Optional) API request timeout in milliseconds. Defaults to `180000` (3 minutes).\n-   `OUTPUT_DIR`: (Optional) Base output directory for generated media files. Defaults to `./output`. Subdirectories like `images`, `audio`, `video` will be created here.\n\n**Default Model Configuration for Image Generation/Editing:**\n-   `DEFAULT_IMAGE_MODEL`: (Optional) Default image generation model. Defaults to `dall-e-3`.\n-   `DEFAULT_EDIT_IMAGE_MODEL`: (Optional) Default image editing model. Defaults to `gpt-image-1`.\n-   `DEFAULT_IMAGE_WIDTH`: (Optional) Default image width (for non-DALL-E 3/gpt-image-1 models). Defaults to `1024`.\n-   `DEFAULT_IMAGE_HEIGHT`: (Optional) Default image height (for non-DALL-E 3/gpt-image-1 models). Defaults to `768`.\n-   `DEFAULT_IMAGE_STEPS`: (Optional) Default image generation steps (for non-DALL-E 3/gpt-image-1 models). Defaults to `20`.\n\n**Default Speech Configuration:**\n-   `DEFAULT_SPEECH_MODEL`: (Optional) Default speech synthesis model. Defaults to `tts-1`.\n-   `DEFAULT_SPEECH_VOICE`: (Optional) Default speech synthesis voice. Defaults to `alloy`.\n-   `DEFAULT_SPEECH_SPEED`: (Optional) Default speech synthesis speed. Defaults to `1.0`.\n-   `DEFAULT_TRANSCRIPTION_MODEL`: (Optional) Default speech transcription model. Defaults to `whisper-1`.\n\n**SiliconFlow Video Generation Configuration:**\n-   `SILICONFLOW_API_KEY`: (Optional, Required if using video generation) SiliconFlow API key.\n-   `SILICONFLOW_BASE_URL`: (Optional) SiliconFlow API base URL. Defaults to `https://api.siliconflow.cn`.\n-   `SILICONFLOW_VIDEO_MODEL`: (Optional) Default video generation model. Defaults to `Wan-AI/Wan2.1-T2V-14B-Turbo`.\n\n**Notification Configuration (configure at least one to receive background task results):**\n-   `ONEBOT_HTTP_URL`: (Optional) OneBot HTTP post URL (e.g., `http://localhost:5700`).\n-   `ONEBOT_ACCESS_TOKEN`: (Optional) OneBot Access Token (if required).\n-   `ONEBOT_MESSAGE_TYPE`: (Optional) OneBot message type (`private` or `group`).\n-   `ONEBOT_TARGET_ID`: (Optional) OneBot target user ID or group ID.\n-   `TELEGRAM_BOT_TOKEN`: (Optional) Telegram Bot Token.\n-   `TELEGRAM_CHAT_ID`: (Optional) Telegram Chat ID.\n\n**ImgBed Configuration (Optional, for `MarSeventh/CloudFlare-ImgBed`):**\n-   `CF_IMGBED_UPLOAD_URL`: (Optional) Your deployed `CloudFlare-ImgBed` upload URL (e.g., `https://your-worker.your-domain.workers.dev/upload`).\n-   `CF_IMGBED_API_KEY`: (Optional) The `AUTH_KEY` (or `authCode` as referred to in some contexts) configured for your `CloudFlare-ImgBed` instance.\n\n## Running the Server\n\n-   **Production Mode**:\n    ```bash\n    npm start\n    ```\n    This will run the JavaScript files from the `build` directory.\n\n-   **Development Mode** (uses ts-node-dev for hot-reloading):\n    ```bash\n    npm run dev\n    ```\n\nOnce started, the MCP server will listen for requests on standard input/output (stdio).\n\n## Available MCP Tools\n\n### 1. `generate_image`\n\nGenerates an image.\n\n-   **Function**: Creates an image based on a text prompt using OpenAI compatible APIs. Supports various models like DALL-E 3, gpt-image-1, and others. For DALL-E 3/gpt-image-1, tasks are processed in the background with results sent via notification. Other models return results synchronously.\n-   **Key Parameters**:\n    -   `prompt` (string, required): Description of the image.\n    -   `model` (string, optional): Model to use, defaults to `DEFAULT_IMAGE_MODEL` from config.\n    -   `n` (number, optional): Number of images to generate.\n    -   (DALL-E 3/gpt-image-1 specific): `quality`, `size`, `background`, `moderation`.\n    -   (Other models specific): `width`, `height`, `steps`.\n\n### 2. `edit_image`\n\nEdits an image.\n\n-   **Function**: Modifies an existing image based on a text prompt using models like `gpt-image-1`. Tasks are processed in the background with results sent via notification.\n-   **Key Parameters**:\n    -   `image` (string, required): Path or URL of the image to edit.\n    -   `prompt` (string, required): Editing instructions.\n    -   `model` (string, optional): Model to use, defaults to `DEFAULT_EDIT_IMAGE_MODEL` from config.\n    -   `n` (number, optional): Number of images to generate.\n    -   `size` (string, optional): Output image size.\n\n### 3. `generate_speech`\n\nText-to-Speech.\n\n-   **Function**: Converts text into an audio file (MP3 format) and saves it locally.\n-   **Key Parameters**:\n    -   `input` (string, required): Text to convert to speech.\n    -   `voice` (string, required): Voice to use.\n    -   `model` (string, optional): Model to use, defaults to `DEFAULT_SPEECH_MODEL` from config.\n    -   `speed` (number, optional): Speech speed, defaults to `DEFAULT_SPEECH_SPEED` from config.\n\n### 4. `transcribe_audio`\n\nSpeech-to-Text.\n\n-   **Function**: Transcribes an audio file into text.\n-   **Key Parameters**:\n    -   `file` (string, required): Local path or URL of the audio file.\n    -   `model` (string, optional): Model to use, defaults to `DEFAULT_TRANSCRIPTION_MODEL` from config.\n\n### 5. `generate_video`\n\nGenerates a video.\n\n-   **Function**: Submits a video generation task to the SiliconFlow API. Supports text-to-video and image-to-video. Tasks are processed in the background with results sent via notification.\n-   **Key Parameters**:\n    -   `prompt` (string, required): Description of the video.\n    -   `image_size` (string, required): Video dimensions/aspect ratio (e.g., \"1280x720\").\n    -   `model` (string, optional): Video model to use, defaults to `SILICONFLOW_VIDEO_MODEL` from config. Supported models include: `Wan-AI/Wan2.1-T2V-14B`, `Wan-AI/Wan2.1-T2V-14B-Turbo`, `Wan-AI/Wan2.1-I2V-14B-720P`, `Wan-AI/Wan2.1-I2V-14B-720P-Turbo`.\n    -   `image` (string, optional): Image URL or Base64 encoded data, required for Image-to-Video models.\n    -   `negative_prompt` (string, optional): Negative prompt.\n    -   `seed` (integer, optional): Random seed.\n\n## Notification Feature\n\nFor tasks processed in the background (e.g., specific image generation/editing, video generation), results will be sent via notifications configured through:\n\n-   **OneBot**: If `ONEBOT_HTTP_URL`, `ONEBOT_MESSAGE_TYPE`, and `ONEBOT_TARGET_ID` are configured.\n-   **Telegram**: If `TELEGRAM_BOT_TOKEN` and `TELEGRAM_CHAT_ID` are configured.\n\nPlease ensure at least one notification method is configured to receive results for background tasks.\n\n## License\n\nThis project is licensed under the MIT License. See the `LICENSE` file for details.\n"
}