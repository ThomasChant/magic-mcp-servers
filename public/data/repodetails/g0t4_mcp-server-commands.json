{
  "mcp_name": "g0t4/mcp-server-commands",
  "mcp_description": "📇 🏠 - Run any command with `run_command` and `run_script` tools.",
  "mcp_id": "g0t4_mcp-server-commands",
  "fetch_timestamp": "2025-06-23T03:39:19.593203Z",
  "github_url": "https://github.com/g0t4/mcp-server-commands",
  "repository": {
    "name": "mcp-server-commands",
    "full_name": "g0t4/mcp-server-commands",
    "description": "Model Context Protocol server to run commands",
    "html_url": "https://github.com/g0t4/mcp-server-commands",
    "created_at": "2024-11-29T02:39:02Z",
    "updated_at": "2025-06-18T11:33:49Z",
    "pushed_at": "2025-06-17T23:28:59Z",
    "size": 184,
    "stargazers_count": 160,
    "watchers_count": 160,
    "forks_count": 27,
    "open_issues_count": 4,
    "language": "TypeScript",
    "license": "MIT License",
    "topics": [],
    "default_branch": "master",
    "owner": {
      "login": "g0t4",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/180189?v=4",
      "html_url": "https://github.com/g0t4"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 27,
    "subscribers_count": 2,
    "languages": {
      "TypeScript": 24441,
      "JavaScript": 8807
    },
    "language_percentages": {
      "TypeScript": 73.51,
      "JavaScript": 26.49
    },
    "pull_requests_count": 4,
    "contributors_count": 1,
    "latest_release": {
      "tag_name": "v0.5.0",
      "name": "0.5.0",
      "published_at": "2025-04-30T12:06:46Z",
      "body": "Merged `run_script` with `run_command` so now there's `stdin` optional argument on `run_command` and that's it for tools! One tool to rule them all. Also updated to newer MCP tool response format to be compatible with clients like Groq Desktop that only use the newer format.",
      "prerelease": false,
      "draft": false
    },
    "tags": [
      {
        "name": "v0.5.0",
        "commit_sha": "fb52a136dda1c2d293280917bf330df21d746846"
      },
      {
        "name": "v0.4.2",
        "commit_sha": "615901e47f4e2a703deaf4fef8df6ef46c95fbb1"
      },
      {
        "name": "v0.4.1",
        "commit_sha": "e24f648a626e320eca9e6bd6c9e5d8e40c1a9baa"
      }
    ],
    "latest_version": "v0.5.0",
    "package_json_version": "0.5.0"
  },
  "readme": "## Tools\n\nTools are for LLMs to request. Claude Sonnet 3.5 intelligently uses `run_command`. And, initial testing shows promising results with [Groq Desktop with MCP](https://github.com/groq/groq-desktop-beta) and `llama4` models.\n\nCurrently, just one command to rule them all!\n\n- `run_command` - run a command, i.e. `hostname` or `ls -al` or `echo \"hello world\"` etc\n  - Returns `STDOUT` and `STDERR` as text\n  - Optional `stdin` parameter means your LLM can\n    - pass code in `stdin` to commands like `fish`, `bash`, `zsh`, `python`\n    - create files with `cat >> foo/bar.txt` from the text in `stdin`\n\n> [!WARNING]\n> Be careful what you ask this server to run!\n> In Claude Desktop app, use `Approve Once` (not `Allow for This Chat`) so you can review each command, use `Deny` if you don't trust the command.\n> Permissions are dictated by the user that runs the server.\n> DO NOT run with `sudo`.\n\n## Video walkthrough\n\n<a href=\"https://youtu.be/0-VPu1Pc18w\"><img src=\"https://img.youtube.com/vi/0-VPu1Pc18w/maxresdefault.jpg\" width=\"480\" alt=\"YouTube Thumbnail\"></a>\n\n## Prompts\n\nPrompts are for users to include in chat history, i.e. via `Zed`'s slash commands (in its AI Chat panel)\n\n- `run_command` - generate a prompt message with the command output\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nGroq Desktop (beta, macOS) uses `~/Library/Application Support/groq-desktop-app/settings.json`\n\n### Use the published npm package\n\nPublished to npm as [mcp-server-commands](https://www.npmjs.com/package/mcp-server-commands) using this [workflow](https://github.com/g0t4/mcp-server-commands/actions)\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-commands\"]\n    }\n  }\n}\n```\n\n### Use a local build (repo checkout)\n\nMake sure to run `npm run build`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      // works b/c of shebang in index.js\n      \"command\": \"/path/to/mcp-server-commands/build/index.js\"\n    }\n  }\n}\n```\n\n## Local Models\n\n- Most models are trained such that they don't think they can run commands for you.\n  - Sometimes, they use tools w/o hesitation... other times, I have to coax them.\n  - Use a system prompt or prompt template to instruct that they should follow user requests. Including to use `run_commands` without double checking.\n- Ollama is a great way to run a model locally (w/ Open-WebUI)\n\n```sh\n# NOTE: make sure to review variants and sizes, so the model fits in your VRAM to perform well!\n\n# Probably the best so far is [OpenHands LM](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model)\nollama pull https://huggingface.co/lmstudio-community/openhands-lm-32b-v0.1-GGUF\n\n# https://ollama.com/library/devstral\nollama pull devstral\n\n# Qwen2.5-Coder has tool use but you have to coax it\nollama pull qwen2.5-coder\n```\n\n### HTTP / OpenAPI\n\nThe server is implemented with the `STDIO` transport.\nFor `HTTP`, use [`mcpo`](https://github.com/open-webui/mcpo) for an `OpenAPI` compatible web server interface.\nThis works with [`Open-WebUI`](https://github.com/open-webui/open-webui)\n\n```bash\nuvx mcpo --port 3010 --api-key \"supersecret\" -- npx mcp-server-commands\n\n# uvx runs mcpo => mcpo run npx => npx runs mcp-server-commands\n# then, mcpo bridges STDIO <=> HTTP\n```\n\n> [!WARNING]\n> I briefly used `mcpo` with `open-webui`, make sure to vet it for security concerns.\n\n### Logging\n\nClaude Desktop app writes logs to `~/Library/Logs/Claude/mcp-server-mcp-server-commands.log`\n\nBy default, only important messages are logged (i.e. errors).\nIf you want to see more messages, add `--verbose` to the `args` when configuring the server.\n\nBy the way, logs are written to `STDERR` because that is what Claude Desktop routes to the log files.\nIn the future, I expect well formatted log messages to be written over the `STDIO` transport to the MCP client (note: not Claude Desktop app).\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n"
}