{
  "mcp_name": "sanxxit/AWS-cost-explorer-with-MCP-server",
  "mcp_description": "Facilitates AWS spend analysis and visualization through an interactive interface using Anthropic's Claude model.",
  "mcp_id": "sanxxit_AWS-cost-explorer-with-MCP-server",
  "fetch_timestamp": "2025-06-23T08:09:56.119094Z",
  "github_url": "https://github.com/sanxxit/AWS-cost-explorer-with-MCP-server",
  "repository": {
    "name": "AWS-cost-explorer-with-MCP-server",
    "full_name": "sanxxit/AWS-cost-explorer-with-MCP-server",
    "description": null,
    "html_url": "https://github.com/sanxxit/AWS-cost-explorer-with-MCP-server",
    "created_at": "2025-04-16T17:17:12Z",
    "updated_at": "2025-05-06T14:38:32Z",
    "pushed_at": "2025-04-16T17:20:45Z",
    "size": 2066,
    "stargazers_count": 1,
    "watchers_count": 1,
    "forks_count": 0,
    "open_issues_count": 0,
    "language": "Python",
    "license": "MIT License",
    "topics": [],
    "default_branch": "main",
    "owner": {
      "login": "sanxxit",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/125626091?v=4",
      "html_url": "https://github.com/sanxxit"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 0,
    "subscribers_count": 1,
    "languages": {
      "Python": 55042,
      "Dockerfile": 391
    },
    "language_percentages": {
      "Python": 99.29,
      "Dockerfile": 0.71
    },
    "pull_requests_count": 0,
    "contributors_count": 2
  },
  "readme": "# AWS Cost Explorer and Amazon Bedrock Model Invocation Logs MCP Server & Client\n\nAn MCP server for getting AWS spend data via Cost Explorer and Amazon Bedrock usage data via [`Model invocation logs`](https://docs.aws.amazon.com/bedrock/latest/userguide/model-invocation-logging.html) in Amazon Cloud Watch through [Anthropic's MCP (Model Control Protocol)](https://www.anthropic.com/news/model-context-protocol). See section on [\"secure\" remote MCP server](#secure-remote-mcp-server) to see how you can run your MCP server over HTTPS.\n\n```mermaid\nflowchart LR\n    User([User]) --> UserApp[User Application]\n    UserApp --> |Queries| Host[Host]\n    \n    subgraph \"Claude Desktop\"\n        Host --> MCPClient[MCP Client]\n    end\n    \n    MCPClient --> |MCP Protocol over HTTPS| MCPServer[AWS Cost Explorer MCP Server]\n    \n    subgraph \"AWS Services\"\n        MCPServer --> |API Calls| CostExplorer[(AWS Cost Explorer)]\n        MCPServer --> |API Calls| CloudWatchLogs[(AWS CloudWatch Logs)]\n    end\n```\n\nYou can run the MCP server locally and access it via the Claude Desktop or you could also run a Remote MCP server on Amazon EC2 and access it via a MCP client built into a LangGraph Agent.\n\nðŸš¨You can also use this MCP server to get AWS spend information from other accounts as long as the IAM role used by the MCP server can assume roles in those other accountsðŸš¨\n\n### Demo video\n\n[![AWS Cost Explorer MCP Server Deep Dive](https://img.youtube.com/vi/WuVOmYLRFmI/maxresdefault.jpg)](https://youtu.be/WuVOmYLRFmI)\n\n## Overview\n\nThis tool provides a convenient way to analyze and visualize AWS cloud spending data using Anthropic's Claude model as an interactive interface. It functions as an MCP server that exposes AWS Cost Explorer API functionality to Claude Desktop, allowing you to ask questions about your AWS spend in natural language.\n\n## Features\n\n- **Amazon EC2 Spend Analysis**: View detailed breakdowns of EC2 spending for the last day\n- **Amazon Bedrock Spend Analysis**: View breakdown by region, users and models over the last 30 days\n- **Service Spend Reports**: Analyze spending across all AWS services for the last 30 days\n- **Detailed Cost Breakdown**: Get granular cost data by day, region, service, and instance type\n- **Interactive Interface**: Use Claude to query your cost data through natural language\n\n## Requirements\n\n- Python 3.12\n- AWS credentials with Cost Explorer access\n- Anthropic API access (for Claude integration)\n- [Optional] Amazon Bedrock access (for LangGraph Agent)\n- [Optional] Amazon EC2 for running a remote MCP server\n\n## Installation\n\n1. Install `uv`:\n   ```bash\n   # On macOS and Linux\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   ```\n   \n   \n   ```powershell\n   # On Windows\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   ```\n   Additional installation options are documented [here](https://docs.astral.sh/uv/getting-started/installation/)\n\n2. Clone this repository: (assuming this will be updated to point to aws-samples?)\n   ```\n   git clone https://github.com/aarora79/aws-cost-explorer-mcp.git\n   cd aws-cost-explorer-mcp\n   ```\n\n3. Set up the Python virtual environment and install dependencies:\n   ```\n   uv venv --python 3.12 && source .venv/bin/activate && uv pip install --requirement pyproject.toml\n   ```\n   \n4. Configure your AWS credentials:\n   ```\n   mkdir -p ~/.aws\n   # Set up your credentials in ~/.aws/credentials and ~/.aws/config\n   ```\n   If you useAWS IAM Identity Center, follow the [docs](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sso.html) to configure your short-term credentials\n\n## Usage\n\n### Prerequisites\n\n1. Setup [model invocation logs](https://docs.aws.amazon.com/bedrock/latest/userguide/model-invocation-logging.html#setup-cloudwatch-logs-destination) in Amazon CloudWatch.\n1. Ensure that the IAM user/role being used has full read-only access to Amazon Cost Explorer and Amazon CloudWatch, this is required for the MCP server to retrieve data from these services.\nSee [here](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-example-policies.html) and [here](https://docs.aws.amazon.com/aws-managed-policy/latest/reference/CloudWatchLogsReadOnlyAccess.html) for sample policy examples that you can use & modify as per your requirements.\n1. To allow your MCP server to access AWS spend information from other accounts set the the `CROSS_ACCOUNT_ROLE_NAME` parameter while starting the server and now you can provide the account AWS account id for another account while interacting with your agent and then agent will pass the account id to the server.\n\n### Local setup\n\nUses `stdio` as a transport for MCP, both the MCP server and client are running on your local machine.\n\n#### Starting the Server (local)\n\nRun the server using:\n\n```\nexport MCP_TRANSPORT=stdio\nexport BEDROCK_LOG_GROUP_NAME=YOUR_BEDROCK_CW_LOG_GROUP_NAME\nexport CROSS_ACCOUNT_ROLE_NAME=ROLE_NAME_FOR_THE_ROLE_TO_ASSUME_IN_OTHER_ACCOUNTS # can be ignored if you do not want AWS spend info from other accounts\npython server.py\n```\n\n#### Claude Desktop Configuration\n\nThere are two ways to configure this tool with Claude Desktop:\n\n##### Option 1: Using Docker\n\nAdd the following to your Claude Desktop configuration file. The file can be found out these paths depending upon you operating system.\n\n- macOS: ~/Library/Application Support/Claude/claude_desktop_config.json.\n- Windows: %APPDATA%\\Claude\\claude_desktop_config.json.\n- Linux: ~/.config/Claude/claude_desktop_config.json.\n\n```json\n{\n  \"mcpServers\": {\n    \"aws-cost-explorer\": {\n      \"command\": \"docker\",\n      \"args\": [ \"run\", \"-i\", \"--rm\", \"-e\", \"AWS_ACCESS_KEY_ID\", \"-e\", \"AWS_SECRET_ACCESS_KEY\", \"-e\", \"AWS_REGION\", \"-e\", \"BEDROCK_LOG_GROUP_NAME\", \"-e\", \"MCP_TRANSPORT\", \"-e\", \"CROSS_ACCOUNT_ROLE_NAME\", \"aws-cost-explorer-mcp:latest\" ],\n      \"env\": {\n        \"AWS_ACCESS_KEY_ID\": \"YOUR_ACCESS_KEY_ID\",\n        \"AWS_SECRET_ACCESS_KEY\": \"YOUR_SECRET_ACCESS_KEY\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"BEDROCK_LOG_GROUP_NAME\": \"YOUR_CLOUDWATCH_BEDROCK_MODEL_INVOCATION_LOG_GROUP_NAME\",\n        \"CROSS_ACCOUNT_ROLE_NAME\": \"ROLE_NAME_FOR_THE_ROLE_TO_ASSUME_IN_OTHER_ACCOUNTS\",\n        \"MCP_TRANSPORT\": \"stdio\"\n      }\n    }\n  }\n}\n```\n\n> **IMPORTANT**: Replace `YOUR_ACCESS_KEY_ID` and `YOUR_SECRET_ACCESS_KEY` with your actual AWS credentials. Never commit actual credentials to version control.\n\n##### Option 2: Using UV (without Docker)\n\nIf you prefer to run the server directly without Docker, you can use UV:\n\n```json\n{\n  \"mcpServers\": {\n    \"aws_cost_explorer\": {\n      \"command\": \"uv\",\n      \"args\": [\n          \"--directory\",\n          \"/path/to/aws-cost-explorer-mcp-server\",\n          \"run\",\n          \"server.py\"\n      ],\n      \"env\": {\n        \"AWS_ACCESS_KEY_ID\": \"YOUR_ACCESS_KEY_ID\",\n        \"AWS_SECRET_ACCESS_KEY\": \"YOUR_SECRET_ACCESS_KEY\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"BEDROCK_LOG_GROUP_NAME\": \"YOUR_CLOUDWATCH_BEDROCK_MODEL_INVOCATION_LOG_GROUP_NAME\",\n        \"CROSS_ACCOUNT_ROLE_NAME\": \"ROLE_NAME_FOR_THE_ROLE_TO_ASSUME_IN_OTHER_ACCOUNTS\",\n        \"MCP_TRANSPORT\": \"stdio\"\n      }\n    }\n  }\n}\n```\n\nMake sure to replace the directory path with the actual path to your repository on your system.\n\n### Remote setup\n\nUses `sse` as a transport for MCP, the MCP servers on EC2 and the client is running on your local machine. Note that Claude Desktop does not support remote MCP servers at this time (see [this](https://github.com/orgs/modelcontextprotocol/discussions/16) GitHub issue).\n\n#### Starting the Server (remote)\n\nYou can start a remote MCP server on Amazon EC2 by following the same instructions as above. Make sure to set the `MCP_TRANSPORT` as `sse` (server side events) as shown below. **Note that the MCP uses JSON-RPC 2.0 as its wire format, therefore the protocol itself does not include authorization and authentication (see [this GitHub issue](https://github.com/modelcontextprotocol/specification/discussions/102)), do not send or receive sensitive data over MCP**.\n\nRun the server using:\n\n```\nexport MCP_TRANSPORT=sse\nexport BEDROCK_LOG_GROUP_NAME=YOUR_BEDROCK_CW_LOG_GROUP_NAME\nexport CROSS_ACCOUNT_ROLE_NAME=ROLE_NAME_FOR_THE_ROLE_TO_ASSUME_IN_OTHER_ACCOUNTS # can be ignored if you do not want AWS spend info from other accounts\npython server.py\n```\n\n1. The MCP server will start listening on TCP port 8000.\n1. Configure an ingress rule in the security group associated with your EC2 instance to allow access to TCP port 8000 from your local machine (where you are running the MCP client/LangGraph based app) to your EC2 instance.\n\n>Also see section on running a [\"secure\" remote MCP server](#secure-remote-mcp-server) i.e. a server to which your MCP clients can connect over HTTPS.\n\n#### Testing with a CLI MCP client\n\nYou can test your remote MCP server with the `mcp_sse_client.py` script. Running this script will print the list of tools available from the MCP server and an output for the `get_bedrock_daily_usage_stats` tool.\n\n```{.bashrc}\n# set the hostname for your MCP server\nMCP_SERVER_HOSTNAME=YOUR_MCP_SERVER_EC2_HOSTNAME\n# or localhost if your MCP server is running locally\n# MCP_SERVER_HOSTNAME=localhost \nAWS_ACCOUNT_ID=AWS_ACCOUNT_ID_TO_GET_INFO_ABOUT # if set to empty or if the --aws-account-id switch is not specified then it gets the info about the AWS account MCP server is running in\npython mcp_sse_client.py --host $MCP_SERVER_HOSTNAME --aws-account-id $AWS_ACCOUNT_ID\n```\n\n\n#### Testing with Chainlit app\n\nThe `app.py` file in this repo provides a Chainlit app (chatbot) which creates a LangGraph agent that uses the [`LangChain MCP Adapter`](https://github.com/langchain-ai/langchain-mcp-adapters) to import the tools provided by the MCP server as tools in a LangGraph Agent. The Agent is then able to use an LLM to respond to user questions and use the tools available to it as needed. Thus if the user asks a question such as \"_What was my Bedrock usage like in the last one week?_\" then the Agent will use the tools available to it via the remote MCP server to answer that question. We use Claude 3.5 Haiku model available via Amazon Bedrock to power this agent.\n\nRun the Chainlit app using:\n\n```{.bashrc}\nchainlit run app.py --port 8080 \n```\n\nA browser window should open up on `localhost:8080` and you should be able to use the chatbot to get details about your AWS spend.\n\n### Available Tools\n\nThe server exposes the following tools that Claude can use:\n\n1. **`get_ec2_spend_last_day()`**: Retrieves EC2 spending data for the previous day\n1. **`get_detailed_breakdown_by_day(days=7)`**: Delivers a comprehensive analysis of costs by region, service, and instance type\n1. **`get_bedrock_daily_usage_stats(days=7, region='us-east-1', log_group_name='BedrockModelInvocationLogGroup')`**: Delivers a per-day breakdown of model usage by region and users.\n1. **`get_bedrock_hourly_usage_stats(days=7, region='us-east-1', log_group_name='BedrockModelInvocationLogGroup')`**: Delivers a per-day per-hour breakdown of model usage by region and users.\n\n### Example Queries\n\nOnce connected to Claude through an MCP-enabled interface, you can ask questions like:\n\n- \"Help me understand my Bedrock spend over the last few weeks\"\n- \"What was my EC2 spend yesterday?\"\n- \"Show me my top 5 AWS services by cost for the last month\"\n- \"Analyze my spending by region for the past 14 days\"\n- \"Which instance types are costing me the most money?\"\n- \"Which services had the highest month-over-month cost increase?\"\n\n## Docker Support\n\nA Dockerfile is included for containerized deployment:\n\n```\ndocker build -t aws-cost-explorer-mcp .\ndocker run -v ~/.aws:/root/.aws aws-cost-explorer-mcp\n```\n\n## Development\n\n### Project Structure\n\n- `server.py`: Main server implementation with MCP tools\n- `pyproject.toml`: Project dependencies and metadata\n- `Dockerfile`: Container definition for deployments\n\n### Adding New Cost Analysis Tools\n\nTo extend the functionality:\n\n1. Add new functions to `server.py`\n2. Annotate them with `@mcp.tool()`\n3. Implement the AWS Cost Explorer API calls\n4. Format the results for easy readability\n\n## Secure \"remote\" MCP server\n\nWe can use [`nginx`](https://nginx.org/) as a reverse-proxy so that it can provide an HTTPS endpoint for connecting to the MCP server. Remote MCP clients can connect to `nginx` over HTTPS and then it can proxy traffic internally to `http://localhost:8000`. The following steps describe how to do this.\n\n1. Enable access to TCP port 443 from the IP address of your MCP client (your laptop, or anywhere) in the inbound rules in the security group associated with your EC2 instance.\n\n1. You would need to have an HTTPS certificate and private key to proceed. Let's say you use `your-mcp-server-domain-name.com` as the domain for your MCP server then you will need an SSL cert for `your-mcp-server-domain-name.com` and it will be accessible to MCP clients as `https://your-mcp-server-domain-name.com/sse`. _While you can use a self-signed cert but it would require disabling SSL verification on the MCP client, we DO NOT recommend you do that_. If you are hosting your MCP server on EC2 then you could generate an SSL cert using [no-ip](https://www.noip.com/) or [Let' Encrypt](https://letsencrypt.org/) or other similar services. Place the SSL cert and private key files in `/etc/ssl/certs` and `/etc/ssl/privatekey` folders respectively on your EC2 machine.\n\n1. Install `nginx` on your EC2 machine using the following commands.\n\n    ```{.bashrc}\n    sudo apt-get install nginx\n    sudo nginx -t\n    sudo systemctl reload nginx\n    ```\n\n1. Get the hostname for your EC2 instance, this would be needed for configuring the `nginx` reverse proxy.\n\n    ```{.bashrc}\n    TOKEN=$(curl -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\") && curl -H \"X-aws-ec2-metadata-token: $TOKEN\" -s http://169.254.169.254/latest/meta-data/public-hostname\n    ```\n\n1. Copy the following content into a new file `/etc/nginx/conf.d/ec2.conf`. Replace `YOUR_EC2_HOSTNAME`, `/etc/ssl/certs/cert.pem` and `/etc/ssl/privatekey/privkey.pem` with values appropriate for your setup.\n\n   ```{.bashrc}\n   server {\n    listen 80;\n    server_name YOUR_EC2_HOSTNAME;\n\n    # Optional: Redirect HTTP to HTTPS\n    return 301 https://$host$request_uri;\n    }\n\n    server {\n        listen 443 ssl;\n        server_name YOUR_EC2_HOSTNAME;\n\n        # Self-signed certificate paths\n        ssl_certificate     /etc/ssl/certs/cert.pem;\n        ssl_certificate_key /etc/ssl/privatekey/privkey.pem; \n\n        # Optional: Good practice\n        ssl_protocols       TLSv1.2 TLSv1.3;\n        ssl_ciphers         HIGH:!aNULL:!MD5;\n\n        location / {\n            # Reverse proxy to your local app (e.g., port 8000)\n            proxy_pass http://127.0.0.1:8000;\n            proxy_http_version 1.1;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n    }\n\n   ```\n\n1. Restart `nginx`.\n\n    ```{.bashrc}\n    sudo systemctl start nginx\n    ```\n\n1. Start your MCP server as usual as described in the [remote setup](#remote-setup) section.\n\n1. Your MCP server is now accessible over HTTPS as `https://your-mcp-server-domain-name.com/sse` to your MCP client.\n\n1. On the client side now (say on your laptop or in your Agent) configure your MCP client to communicate to your MCP server as follows.\n\n    ```{.bashrc}\n    MCP_SERVER_HOSTNAME=YOUR_MCP_SERVER_DOMAIN_NAME\n    AWS_ACCOUNT_ID=AWS_ACCOUNT_ID_TO_GET_INFO_ABOUT # if set to empty or if the --aws-account-id switch is not specified then it gets the info about the AWS account MCP server is running in\n    python mcp_sse_client.py --host $MCP_SERVER_HOSTNAME --port 443 --aws-account-id $AWS_ACCOUNT_ID\n    ```\n\n    Similarly you could run the chainlit app to talk to remote MCP server over HTTPS.\n\n    ```{.bashrc}\n    export MCP_SERVER_URL=YOUR_MCP_SERVER_DOMAIN_NAME\n    export MCP_SERVER_PORT=443\n    chainlit run app.py --port 8080\n    ```\n\n    Similarly you could run the LangGraph Agent to talk to remote MCP server over HTTPS.\n\n    ```{.bashrc}    \n    python langgraph_agent_mcp_sse_client.py --host $MCP_SERVER_HOSTNAME --port 443 --aws-account-id $AWS_ACCOUNT_ID\n    ```\n\n## License\n\n[MIT License](LICENSE)\n\n## Acknowledgments\n\n- This tool uses Anthropic's MCP framework\n- Powered by AWS Cost Explorer API\n- Built with [FastMCP](https://github.com/jlowin/fastmcp) for server implementation\n- README was generated by providing a text dump of the repo via [GitIngest](https://gitingest.com/) to Claude\n"
}