{
  "mcp_name": "arrismo/kaggle-mcp",
  "mcp_description": "Facilitates interaction with Kaggle by providing tools for dataset search, download, and EDA notebook generation via the Model Context Protocol.",
  "mcp_id": "arrismo_kaggle-mcp",
  "fetch_timestamp": "2025-06-23T01:17:38.406685Z",
  "github_url": "https://github.com/arrismo/kaggle-mcp",
  "repository": {
    "name": "kaggle-mcp",
    "full_name": "arrismo/kaggle-mcp",
    "description": "MCP server for Kaggle",
    "html_url": "https://github.com/arrismo/kaggle-mcp",
    "created_at": "2025-04-11T03:01:18Z",
    "updated_at": "2025-06-09T11:31:04Z",
    "pushed_at": "2025-05-05T01:19:58Z",
    "size": 77,
    "stargazers_count": 12,
    "watchers_count": 12,
    "forks_count": 4,
    "open_issues_count": 0,
    "language": "Python",
    "license": "MIT License",
    "topics": [
      "kaggle",
      "mcp-server"
    ],
    "default_branch": "main",
    "owner": {
      "login": "arrismo",
      "type": "User",
      "avatar_url": "https://avatars.githubusercontent.com/u/46009365?v=4",
      "html_url": "https://github.com/arrismo"
    },
    "has_issues": true,
    "has_projects": true,
    "has_downloads": true,
    "has_wiki": true,
    "has_pages": false,
    "archived": false,
    "disabled": false,
    "visibility": "public",
    "network_count": 4,
    "subscribers_count": 1,
    "languages": {
      "Python": 7323,
      "Dockerfile": 919
    },
    "language_percentages": {
      "Python": 88.85,
      "Dockerfile": 11.15
    },
    "pull_requests_count": 0,
    "contributors_count": 1
  },
  "readme": "[![smithery badge](https://smithery.ai/badge/@arrismo/kaggle-mcp)](https://smithery.ai/server/@arrismo/kaggle-mcp)\n<a href=\"https://glama.ai/mcp/servers/arwswog1el\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/arwswog1el/badge\" alt=\"Kaggle MCP Server\" /></a>\n\n# Kaggle MCP (Model Context Protocol) Server\nThis repository contains an MCP (Model Context Protocol) server (`server.py`) built using the `fastmcp` library. It interacts with the Kaggle API to provide tools for searching and downloading datasets, and a prompt for generating EDA notebooks.\n\n## Project Structure\n\n-   `server.py`: The FastMCP server application. It defines resources, tools, and prompts for interacting with Kaggle.\n-   `.env.example`: An example file for environment variables (Kaggle API credentials). Rename to `.env` and fill in your details.\n-   `requirements.txt`: Lists the necessary Python packages.\n-   `pyproject.toml` & `uv.lock`: Project metadata and locked dependencies for `uv` package manager.\n-   `datasets/`: Default directory where downloaded Kaggle datasets will be stored.\n\n## Setup\n\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd <repository-directory>\n    ```\n\n2.  **Create a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    # Or use uv: uv venv\n    ```\n\n3.  **Install dependencies:**\n    Using pip:\n    ```bash\n    pip install -r requirements.txt\n    ```\n    Or using uv:\n    ```bash\n    uv sync\n    ```\n\n4.  **Set up Kaggle API credentials:**\n    -   **Method 1 (Recommended): Environment Variables**\n        -   Create `.env` file\n        -   Open the `.env` file and add your Kaggle username and API key:\n            ```dotenv\n            KAGGLE_USERNAME=your_kaggle_username\n            KAGGLE_KEY=your_kaggle_api_key\n            ```\n        -   You can obtain your API key from your Kaggle account page (`Account` > `API` > `Create New API Token`). This will download a `kaggle.json` file containing your username and key.\n    -   **Method 2: `kaggle.json` file**\n        -   Download your `kaggle.json` file from your Kaggle account.\n        -   Place the `kaggle.json` file in the expected location (usually `~/.kaggle/kaggle.json` on Linux/macOS or `C:\\Users\\<Your User Name>\\.kaggle\\kaggle.json` on Windows). The `kaggle` library will automatically detect this file if the environment variables are not set.\n\n## Running the Server\n\n1.  **Ensure your virtual environment is active.**\n2.  **Run the MCP server:**\n    ```bash\n    uv run kaggle-mcp\n    ```\n    The server will start and register its resources, tools, and prompts. You can interact with it using an MCP client or compatible tools.\n\n## Running the Docker Container\n\n### 1. Set up Kaggle API credentials\n\nThis project requires Kaggle API credentials to access Kaggle datasets.\n\n- Go to https://www.kaggle.com/settings and click \"Create New API Token\" to download your `kaggle.json` file.\n- Open the `kaggle.json` file and copy your username and key into a new `.env` file in the project root:\n\n```\nKAGGLE_USERNAME=your_username\nKAGGLE_KEY=your_key\n```\n\n### 2. Build the Docker image\n\n```sh\ndocker build -t kaggle-mcp-test .\n```\n\n### 3. Run the Docker container using your .env file\n\n```sh\ndocker run --rm -it --env-file .env kaggle-mcp-test\n```\n\nThis will automatically load your Kaggle credentials as environment variables inside the container.\n\n---\n\n\n## Server Features\n\nThe server exposes the following capabilities through the Model Context Protocol:\n### Tools\n\n*   **`search_kaggle_datasets(query: str)`**:\n    *   Searches for datasets on Kaggle matching the provided query string.\n    *   Returns a JSON list of the top 10 matching datasets with details like reference, title, download count, and last updated date.\n*   **`download_kaggle_dataset(dataset_ref: str, download_path: str | None = None)`**:\n    *   Downloads and unzips files for a specific Kaggle dataset.\n    *   `dataset_ref`: The dataset identifier in the format `username/dataset-slug` (e.g., `kaggle/titanic`).\n    *   `download_path` (Optional): Specifies where to download the dataset. If omitted, it defaults to `./datasets/<dataset_slug>/` relative to the server script's location.\n\n### Prompts\n\n*   **`generate_eda_notebook(dataset_ref: str)`**:\n    *   Generates a prompt message suitable for an AI model (like Gemini) to create a basic Exploratory Data Analysis (EDA) notebook for the specified Kaggle dataset reference.\n    *   The prompt asks for Python code covering data loading, missing value checks, visualizations, and basic statistics.\n\n## Connecting to Claude Desktop \nGo to Claude > Settings > Developer > Edit Config > claude_desktop_config.json to include the following:\n\n```\n{\n  \"mcpServers\": {\n    \"kaggle-mcp\": {\n      \"command\": \"kaggle-mcp\",\n      \"cwd\": \"<path-to-their-cloned-repo>/kaggle-mcp\"\n    }\n  }\n}\n```\n\n## Usage Example\n\nAn AI agent or MCP client could interact with this server like this:\n\n1.  **Agent:** \"Search Kaggle for datasets about 'heart disease'\"\n    *   *Server executes `search_kaggle_datasets(query='heart disease')`*\n2.  **Agent:** \"Download the dataset 'user/heart-disease-dataset'\"\n    *   *Server executes `download_kaggle_dataset(dataset_ref='user/heart-disease-dataset')`*\n3.  **Agent:** \"Generate an EDA notebook prompt for 'user/heart-disease-dataset'\"\n    *   *Server executes `generate_eda_notebook(dataset_ref='user/heart-disease-dataset')`*\n    *   *Server returns a structured prompt message.*\n4.  **Agent:** (Sends the prompt to a code-generating model) -> Receives EDA Python code.\n"
}